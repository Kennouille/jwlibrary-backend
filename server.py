from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from datetime import datetime
import os
import zipfile
import sqlite3
import shutil
import uuid
import time
import sys


app = Flask(__name__)
app.config['PROPAGATE_EXCEPTIONS'] = True
CORS(app, origins=["https://jwmerge.netlify.app"])

UPLOAD_FOLDER = "uploads"
EXTRACT_FOLDER = "extracted"

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(EXTRACT_FOLDER, exist_ok=True)


def normalize_mapping_keys(mapping):
    return {
        (os.path.normpath(k[0]), k[1]): v
        for k, v in mapping.items()
    }


def get_current_local_iso8601():
    now_local = datetime.datetime.now()
    return now_local.strftime("%Y-%m-%dT%H:%M:%S")


def checkpoint_db(db_path):
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("PRAGMA wal_checkpoint(FULL)")
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"Erreur lors du checkpoint de {db_path}: {e}")


def list_tables(db_path):
    """
    Retourne une liste des noms de tables pr√©sentes dans la base de donn√©es
    sp√©cifi√©e par 'db_path', en excluant les tables syst√®me (commen√ßant par 'sqlite_').
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT name
        FROM sqlite_master
        WHERE type='table'
          AND name NOT LIKE 'sqlite_%'
    """)
    tables = [row[0] for row in cursor.fetchall()]
    conn.close()
    return tables


def merge_independent_media(merged_db_path, file1_db, file2_db):
    """
    Fusionne la table IndependentMedia des deux bases sources dans la base fusionn√©e.
    Deux lignes sont consid√©r√©es identiques si (OriginalFilename, FilePath, Hash) sont identiques.
    Si une ligne existe d√©j√†, on ignore la nouvelle pour pr√©server les donn√©es existantes.
    Retourne un mapping : {(db_source, ancien_ID) : nouveau_ID, ...}
    """
    print("\n[FUSION INDEPENDENTMEDIA]")
    mapping = {}
    with sqlite3.connect(merged_db_path) as merged_conn:
        merged_cursor = merged_conn.cursor()

        for db_path in [file1_db, file2_db]:
            print(f"Traitement de {db_path}")
            with sqlite3.connect(db_path) as src_conn:
                src_cursor = src_conn.cursor()
                src_cursor.execute("""
                    SELECT IndependentMediaId, OriginalFilename, FilePath, MimeType, Hash
                    FROM IndependentMedia
                """)
                rows = src_cursor.fetchall()

                for row in rows:
                    old_id, orig_fn, file_path, mime, hash_val = row
                    print(f"  - M√©dia : {orig_fn}, Hash={hash_val}")

                    # V√©rifie si la ligne existe d√©j√† (√©vite doublons)
                    merged_cursor.execute("""
                        SELECT IndependentMediaId, MimeType
                        FROM IndependentMedia
                        WHERE OriginalFilename = ? AND FilePath = ? AND Hash = ?
                    """, (orig_fn, file_path, hash_val))
                    result = merged_cursor.fetchone()

                    if result:
                        new_id, existing_mime = result
                        # Au lieu de mettre √† jour le MimeType, on ignore simplement la nouvelle ligne
                        print(f"    > Ligne d√©j√† pr√©sente pour ID {new_id} (ignor√©e pour {db_path})")
                    else:
                        merged_cursor.execute("""
                            INSERT INTO IndependentMedia (OriginalFilename, FilePath, MimeType, Hash)
                            VALUES (?, ?, ?, ?)
                        """, (orig_fn, file_path, mime, hash_val))
                        new_id = merged_cursor.lastrowid
                        print(f"    > Insertion nouvelle ligne ID {new_id}")

                    mapping[(db_path, old_id)] = new_id

        merged_conn.commit()

    print("Fusion IndependentMedia termin√©e.")
    return mapping


def read_notes_and_highlights(db_path):
    if not os.path.exists(db_path):
        return {"error": f"Base de donn√©es introuvable : {db_path}"}
    checkpoint_db(db_path)
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        SELECT n.NoteId, n.Guid, n.Title, n.Content, n.LocationId, um.UserMarkGuid,
               n.LastModified, n.Created, n.BlockType, n.BlockIdentifier
        FROM Note n
        LEFT JOIN UserMark um ON n.UserMarkId = um.UserMarkId
    """)
    notes = cursor.fetchall()

    cursor.execute("""
        SELECT UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version
        FROM UserMark
    """)
    highlights = cursor.fetchall()

    conn.close()
    return {"notes": notes, "highlights": highlights}


def extract_file(file_path, extract_folder):
    zip_path = file_path.replace(".jwlibrary", ".zip")
    if os.path.exists(zip_path):
        os.remove(zip_path)
    os.rename(file_path, zip_path)
    extract_full_path = os.path.join(EXTRACT_FOLDER, extract_folder)
    os.makedirs(extract_full_path, exist_ok=True)
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_full_path)
    return extract_full_path


def create_merged_schema(merged_db_path, base_db_path):
    checkpoint_db(base_db_path)
    src_conn = sqlite3.connect(base_db_path)
    src_cursor = src_conn.cursor()
    src_cursor.execute(
        "SELECT type, name, sql FROM sqlite_master "
        "WHERE type IN ('table', 'index', 'trigger', 'view') "
        "AND name NOT LIKE 'sqlite_%'"
    )
    schema_items = src_cursor.fetchall()
    src_conn.close()

    merged_conn = sqlite3.connect(merged_db_path)
    merged_cursor = merged_conn.cursor()
    for obj_type, name, sql in schema_items:
        # On exclut la table (et triggers associ√©s) LastModified
        if (obj_type == 'table' and name == "LastModified") or (obj_type == 'trigger' and "LastModified" in sql):
            continue
        if sql:
            try:
                merged_cursor.execute(sql)
            except Exception as e:
                print(f"Erreur lors de la cr√©ation de {obj_type} '{name}': {e}")
    merged_conn.commit()

    try:
        merged_cursor.execute("DROP TABLE IF EXISTS LastModified")
        merged_cursor.execute("CREATE TABLE LastModified (LastModified TEXT NOT NULL)")
    except Exception as e:
        print(f"Erreur lors de la cr√©ation de la table LastModified: {e}")
    merged_conn.commit()

    # Cr√©ation correcte de PlaylistItemMediaMap si elle n'existe pas
    merged_cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name='PlaylistItemMediaMap'"
    )
    if not merged_cursor.fetchone():
        merged_cursor.execute("""
            CREATE TABLE PlaylistItemMediaMap (
                PlaylistItemId   INTEGER NOT NULL,
                MediaFileId      INTEGER NOT NULL,
                OrderIndex       INTEGER NOT NULL,
                PRIMARY KEY (PlaylistItemId, MediaFileId),
                FOREIGN KEY (PlaylistItemId) REFERENCES PlaylistItem(PlaylistItemId),
                FOREIGN KEY (MediaFileId)  REFERENCES IndependentMedia(IndependentMediaId)
            )
        """)
        print("PlaylistItemMediaMap (avec MediaFileId, OrderIndex) cr√©√©e dans la base fusionn√©e.")

    merged_conn.commit()
    merged_conn.close()


def create_table_if_missing(merged_conn, source_db_paths, table):
    cursor = merged_conn.cursor()
    cursor.execute(f"PRAGMA table_info({table})")
    if cursor.fetchone() is None:
        create_sql = None
        for db_path in source_db_paths:
            checkpoint_db(db_path)
            src_conn = sqlite3.connect(db_path)
            src_cursor = src_conn.cursor()
            src_cursor.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name=?", (table,))
            row = src_cursor.fetchone()
            src_conn.close()
            if row and row[0]:
                create_sql = row[0]
                break
        if create_sql:
            try:
                merged_conn.execute(create_sql)
                print(f"Table {table} cr√©√©e dans la base fusionn√©e.")
            except Exception as e:
                print(f"Erreur lors de la cr√©ation de {table}: {e}")
        else:
            print(f"Aucun sch√©ma trouv√© pour la table {table} dans les bases sources.")


def merge_other_tables(merged_db_path, db1_path, db2_path, exclude_tables=None):
    """
    Fusionne toutes les tables restantes (hors celles sp√©cifi√©es dans exclude_tables)
    dans la base fusionn√©e de mani√®re idempotente.
    Pour chaque table, la fonction v√©rifie si une ligne identique (comparaison sur toutes
    les colonnes sauf la cl√© primaire) est d√©j√† pr√©sente avant insertion.
    """
    if exclude_tables is None:
        exclude_tables = ["Note", "UserMark", "Bookmark", "InputField"]

    # On effectue un checkpoint pour s'assurer que les donn√©es sont bien synchronis√©es.
    checkpoint_db(db1_path)
    checkpoint_db(db2_path)

    def get_tables(path):
        with sqlite3.connect(path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
            return {row[0] for row in cursor.fetchall()}

    tables1 = get_tables(db1_path)
    tables2 = get_tables(db2_path)
    all_tables = (tables1 | tables2) - set(exclude_tables)

    merged_conn = sqlite3.connect(merged_db_path)
    merged_cursor = merged_conn.cursor()
    source_db_paths = [db1_path, db2_path]

    for table in all_tables:
        # Cr√©e la table dans la DB fusionn√©e si elle est manquante
        create_table_if_missing(merged_conn, source_db_paths, table)
        merged_cursor.execute(f"PRAGMA table_info({table})")
        columns_info = merged_cursor.fetchall()
        if not columns_info:
            print(f"‚ùå Table {table} introuvable dans la DB fusionn√©e.")
            continue

        # R√©cup√©ration de la liste des colonnes (on suppose que la premi√®re colonne est la cl√© primaire)
        columns = [col[1] for col in columns_info]
        columns_joined = ", ".join(columns)
        placeholders = ", ".join(["?"] * len(columns))

        # Pour chaque source, ins√©rer les lignes qui n'existent pas d√©j√†
        for source_path in source_db_paths:
            with sqlite3.connect(source_path) as src_conn:
                src_cursor = src_conn.cursor()
                try:
                    src_cursor.execute(f"SELECT * FROM {table}")
                    rows = src_cursor.fetchall()
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lecture de {table} depuis {source_path}: {e}")
                    rows = []
                for row in rows:
                    # On ignore la premi√®re colonne (cl√© primaire) lors de la comparaison
                    where_clause = " AND ".join([f"{col}=?" for col in columns[1:]])
                    check_query = f"SELECT 1 FROM {table} WHERE {where_clause} LIMIT 1"
                    merged_cursor.execute(check_query, row[1:])
                    exists = merged_cursor.fetchone()
                    if not exists:
                        # Si la ligne n'existe pas, on d√©termine la nouvelle cl√©
                        cur_max = merged_cursor.execute(f"SELECT MAX({columns[0]}) FROM {table}").fetchone()[0] or 0
                        new_id = cur_max + 1
                        new_row = (new_id,) + row[1:]
                        print(f"‚úÖ INSERT dans {table} depuis {source_path}: {new_row}")
                        merged_cursor.execute(f"INSERT INTO {table} ({columns_joined}) VALUES ({placeholders})",
                                              new_row)
                    else:
                        print(f"‚è© Doublon ignor√© dans {table} depuis {source_path}: {row[1:]}")
    merged_conn.commit()
    merged_conn.close()


def merge_bookmarks(merged_db_path, file1_db, file2_db, location_id_map):
    """
    Fusionne les bookmarks depuis les deux fichiers sources dans la base fusionn√©e,
    de fa√ßon idempotente.
    Pour chaque bookmark, un mapping (SourceDb, OldID) -> NewID est enregistr√© dans
    la table MergeMapping_Bookmark. En cas de conflit sur (PublicationLocationId, Slot),
    le Slot est incr√©ment√© jusqu'√† trouver une valeur libre.
    Retourne un mapping { (db_source, old_id): new_id }.
    """
    print("\n[FUSION BOOKMARKS - ID√âMPOTENT]")
    mapping = {}
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # Cr√©er la table de mapping pour Bookmark si elle n'existe pas d√©j√†
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_Bookmark (
            SourceDb TEXT,
            OldID INTEGER,
            NewID INTEGER,
            PRIMARY KEY (SourceDb, OldID)
        )
    """)
    conn.commit()

    # Liste des fichiers sources √† traiter
    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()

            # V√©rifie si la table Bookmark existe dans le fichier source
            src_cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='Bookmark'")
            if not src_cursor.fetchone():
                print(f"Aucune table Bookmark trouv√©e dans {db_path}")
                continue

            src_cursor.execute("""
                SELECT BookmarkId, LocationId, PublicationLocationId, Slot, Title, 
                       Snippet, BlockType, BlockIdentifier
                FROM Bookmark
            """)
            for row in src_cursor.fetchall():
                old_id, loc_id, pub_loc_id, slot, title, snippet, block_type, block_id = row

                # V√©rifier si cet enregistrement a d√©j√† √©t√© fusionn√©
                cursor.execute("""
                    SELECT NewID FROM MergeMapping_Bookmark
                    WHERE SourceDb = ? AND OldID = ?
                """, (db_path, old_id))
                res = cursor.fetchone()
                if res:
                    new_id = res[0]
                    print(f"Bookmark d√©j√† fusionn√© pour OldID {old_id} dans {db_path} -> NewID {new_id}")
                    mapping[(db_path, old_id)] = new_id
                    continue

                # Appliquer le mapping sur LocationId et PublicationLocationId
                new_loc_id = location_id_map.get((db_path, loc_id), loc_id)
                new_pub_loc_id = location_id_map.get((db_path, pub_loc_id), pub_loc_id)

                # V√©rifier que les LocationIds existent dans la DB fusionn√©e
                cursor.execute("SELECT 1 FROM Location WHERE LocationId IN (?, ?)", (new_loc_id, new_pub_loc_id))
                if len(cursor.fetchall()) != 2:
                    print(
                        f"‚ö†Ô∏è LocationId introuvable pour Bookmark OldID {old_id} dans {db_path} (LocationId {new_loc_id} ou PublicationLocationId {new_pub_loc_id}), bookmark ignor√©.")
                    continue

                # V√©rifier et ajuster le slot pour √©viter les conflits
                original_slot = slot
                while True:
                    cursor.execute("""
                        SELECT BookmarkId FROM Bookmark
                        WHERE PublicationLocationId = ? AND Slot = ?
                    """, (new_pub_loc_id, slot))
                    if not cursor.fetchone():
                        break
                    print(
                        f"Conflit d√©tect√© pour PublicationLocationId={new_pub_loc_id}, Slot={slot}. Incr√©mentation du slot.")
                    slot += 1

                print(
                    f"Insertion Bookmark: OldID {old_id} (slot initial {original_slot} -> {slot}), PubLocId {new_pub_loc_id}, Title='{title}'")
                cursor.execute("""
                    INSERT INTO Bookmark
                    (LocationId, PublicationLocationId, Slot, Title,
                     Snippet, BlockType, BlockIdentifier)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (new_loc_id, new_pub_loc_id, slot, title, snippet, block_type, block_id))
                new_id = cursor.lastrowid
                mapping[(db_path, old_id)] = new_id

                # Enregistrer le mapping dans la table d√©di√©e
                cursor.execute("""
                    INSERT INTO MergeMapping_Bookmark (SourceDb, OldID, NewID)
                    VALUES (?, ?, ?)
                """, (db_path, old_id, new_id))
                conn.commit()

    conn.close()
    print("Fusion Bookmarks termin√©e (idempotente).")
    return mapping


def merge_notes(merged_db_path, file1_db, file2_db, location_id_map, usermark_guid_map):
    """
    Fusionne la table Note de fa√ßon √† ne pas √©craser les donn√©es existantes.
    Si une note avec le m√™me GUID existe d√©j√† mais que le contenu diff√®re,
    on ins√®re une nouvelle note avec un nouveau GUID et on laisse en place la note existante.
    """
    print("\n=== FUSION DES NOTES (r√©solution de conflit par insertion) ===")
    inserted = 0

    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # On it√®re d'abord sur file1, puis sur file2
    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT n.Guid, um.UserMarkGuid, n.LocationId, n.Title, n.Content,
                       n.LastModified, n.Created, n.BlockType, n.BlockIdentifier
                FROM Note n
                LEFT JOIN UserMark um ON n.UserMarkId = um.UserMarkId
            """)
            for (guid, usermark_guid, location_id, title, content,
                 last_modified, created, block_type, block_identifier) in src_cursor.fetchall():

                # Appliquer les mappings sur LocationId et UserMarkId
                normalized_key = (os.path.normpath(db_path), location_id)
                normalized_map = {(os.path.normpath(k[0]), k[1]): v for k, v in location_id_map.items()}
                new_location_id = normalized_map.get(normalized_key) if location_id else None

                new_usermark_id = usermark_guid_map.get(usermark_guid) if usermark_guid else None

                if new_location_id is None:
                    print(f"‚ö†Ô∏è LocationId introuvable pour Note guid={guid} (source: {db_path}), ignor√©e.")
                    continue

                # V√©rifier l'existence d'une note avec ce GUID dans la DB fusionn√©e
                cursor.execute("SELECT Title, Content FROM Note WHERE Guid = ?", (guid,))
                existing = cursor.fetchone()

                if existing:
                    # Si le contenu est identique, on ne fait rien
                    if existing[0] == title and existing[1] == content:
                        print(f"Note guid={guid} d√©j√† pr√©sente et identique (source: {db_path}), aucune action.")
                        continue
                    else:
                        # Conflit d√©tect√© : le GUID existe mais le contenu est diff√©rent.
                        # On g√©n√®re alors un nouveau GUID pour ins√©rer la note sans √©craser l'existante.
                        new_guid = str(uuid.uuid4())
                        print(f"Conflit pour Note guid={guid} (source: {db_path}). "
                              f"Insertion d'une nouvelle note avec nouveau GUID {new_guid}.")
                        guid_to_insert = new_guid
                else:
                    guid_to_insert = guid

                # Insertion de la note (soit en conservant le GUID, soit avec un nouveau)
                cursor.execute("""
                    INSERT INTO Note
                    (Guid, UserMarkId, LocationId, Title, Content,
                     LastModified, Created, BlockType, BlockIdentifier)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    guid_to_insert,
                    new_usermark_id,
                    new_location_id,
                    title,
                    content,
                    last_modified,
                    created,
                    block_type,
                    block_identifier
                ))
                inserted += 1

    conn.commit()
    conn.close()
    print(f"‚úÖ Total notes ins√©r√©es: {inserted}")


def merge_usermark_with_id_relabeling(merged_db_path, source_db_path, location_id_map):
    conn_merged = sqlite3.connect(merged_db_path)
    cur_merged = conn_merged.cursor()

    # R√©cup√®re les IDs existants pour √©viter les conflits
    cur_merged.execute("SELECT UserMarkId FROM UserMark")
    existing_ids = set(row[0] for row in cur_merged.fetchall())
    current_max_id = max(existing_ids) if existing_ids else 0

    # Charge les donn√©es source
    conn_source = sqlite3.connect(source_db_path)
    cur_source = conn_source.cursor()
    cur_source.execute("SELECT UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version FROM UserMark")
    source_rows = cur_source.fetchall()
    conn_source.close()

    # Cr√©ation du mapping UserMarkId (si conflits)
    replacements = {}
    for row in source_rows:
        old_id = row[0]
        if old_id in existing_ids:
            current_max_id += 1
            new_id = current_max_id
            replacements[old_id] = new_id
        else:
            replacements[old_id] = old_id
            existing_ids.add(old_id)

    # Insertion dans la base fusionn√©e avec LocationId mapp√©
    for row in source_rows:
        old_id = row[0]
        new_id = replacements[old_id]
        ColorIndex = row[1]
        LocationId = row[2]
        StyleIndex = row[3]
        UserMarkGuid = row[4]
        Version = row[5]

        # Mapping du LocationId
        mapped_loc_id = location_id_map.get((source_db_path, LocationId), LocationId)

        try:
            cur_merged.execute("""
                INSERT INTO UserMark (UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (new_id, ColorIndex, mapped_loc_id, StyleIndex, UserMarkGuid, Version))
        except Exception as e:
            print(f"Erreur insertion UserMark old_id={old_id}, new_id={new_id}: {e}")

    conn_merged.commit()
    conn_merged.close()
    return replacements


def merge_blockrange_from_two_sources(merged_db_path, file1_db, file2_db):
    print("\n=== FUSION BLOCKRANGE ===")

    # 1) V√©rification initiale
    with sqlite3.connect(merged_db_path) as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM BlockRange")
        print(f"BlockRanges initiaux: {cursor.fetchone()[0]}")

    # 2) R√©cup√©ration des mappings
    try:
        with sqlite3.connect(merged_db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT UserMarkId, UserMarkGuid FROM UserMark")
            usermark_guid_map = {guid: uid for uid, guid in cursor.fetchall()}
            print(f"UserMark GUIDs: {usermark_guid_map}")
    except Exception as e:
        print(f"‚ùå Erreur mapping UserMark: {e}")
        return False

    # 3) Traitement des sources
    with sqlite3.connect(merged_db_path) as dest_conn:
        dest_cursor = dest_conn.cursor()

        for db_path in [file1_db, file2_db]:
            print(f"\nTraitement de {db_path}")
            try:
                with sqlite3.connect(db_path) as src_conn:
                    src_cursor = src_conn.cursor()

                    # Requ√™te optimis√©e
                    src_cursor.execute("""
                        SELECT br.BlockType, br.Identifier, br.StartToken, br.EndToken, um.UserMarkGuid
                        FROM BlockRange br
                        JOIN UserMark um ON br.UserMarkId = um.UserMarkId
                        ORDER BY br.BlockType, br.Identifier
                    """)

                    for row in src_cursor.fetchall():
                        block_type, identifier, start_token, end_token, usermark_guid = row
                        new_usermark_id = usermark_guid_map.get(usermark_guid)

                        if not new_usermark_id:
                            print(f"‚ö†Ô∏è GUID non mapp√©: {usermark_guid}")
                            continue

                        try:
                            # V√©rification d'existence
                            dest_cursor.execute("""
                                SELECT 1 FROM BlockRange
                                WHERE BlockType=? AND Identifier=? AND UserMarkId=?
                                AND StartToken=? AND EndToken=?
                            """, (block_type, identifier, new_usermark_id, start_token, end_token))

                            if dest_cursor.fetchone():
                                print(f"‚è© Existe d√©j√†: {row}")
                                continue

                            # Insertion
                            dest_cursor.execute("""
                                INSERT INTO BlockRange
                                (BlockType, Identifier, StartToken, EndToken, UserMarkId)
                                VALUES (?, ?, ?, ?, ?)
                            """, (block_type, identifier, start_token, end_token, new_usermark_id))

                            dest_conn.commit()
                            print(f"‚úÖ Insert√©: {row}")

                        except sqlite3.IntegrityError as e:
                            dest_conn.rollback()
                            print(f"‚ùå Erreur int√©grit√©: {e}")
                            print(f"Ligne probl√©matique: {row}")
                            # Debug avanc√©
                            dest_cursor.execute("PRAGMA foreign_key_check")
                            print("Probl√®mes cl√©s √©trang√®res:", dest_cursor.fetchall())
                            return False

            except Exception as e:
                print(f"‚ùå Erreur fichier {db_path}: {e}")
                return False

        # V√©rification finale
        dest_cursor.execute("SELECT COUNT(*) FROM BlockRange")
        print(f"Total BlockRanges apr√®s fusion: {dest_cursor.fetchone()[0]}")

    return True


def merge_inputfields(merged_db_path, file1_db, file2_db, location_id_map):
    print("\n[FUSION INPUTFIELD - ID√âMPOTENTE]")
    inserted_count = 0
    skipped_count = 0
    missing_count = 0

    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # Cr√©er la table de mapping pour InputField si elle n'existe pas d√©j√†
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_InputField (
            SourceDb TEXT,
            OldLocationId INTEGER,
            TextTag TEXT,
            Value TEXT,
            PRIMARY KEY (SourceDb, OldLocationId, TextTag)
        )
    """)
    conn.commit()

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("SELECT LocationId, TextTag, Value FROM InputField")
            rows = src_cursor.fetchall()

            for loc_id, tag, value in rows:
                # Appliquer le mapping de LocationId pour ce fichier source
                mapped_loc = location_id_map.get((db_path, loc_id))
                if mapped_loc is None:
                    print(f"‚ùå LocationId {loc_id} (depuis {db_path}) non mapp√© ‚Äî ligne ignor√©e")
                    missing_count += 1
                    continue

                # V√©rifier dans la table de mapping si cette entr√©e a d√©j√† √©t√© fusionn√©e
                cursor.execute("""
                    SELECT 1 FROM MergeMapping_InputField 
                    WHERE SourceDb = ? AND OldLocationId = ? AND TextTag = ?
                """, (db_path, loc_id, tag))
                if cursor.fetchone():
                    print(f"‚è© InputField d√©j√† fusionn√©e : Source={db_path}, OldLocId={loc_id}, Tag={tag}")
                    skipped_count += 1
                    continue

                # V√©rifier si une ligne identique est d√©j√† pr√©sente dans la table InputField de la DB fusionn√©e
                cursor.execute("""
                    SELECT 1 FROM InputField
                    WHERE LocationId = ? AND TextTag = ? AND Value = ?
                """, (mapped_loc, tag, value))
                if cursor.fetchone():
                    print(f"‚è© Doublon d√©tect√© dans InputField pour Loc={mapped_loc}, Tag={tag} (ajout mapping)")
                    cursor.execute("""
                        INSERT OR IGNORE INTO MergeMapping_InputField (SourceDb, OldLocationId, TextTag, Value)
                        VALUES (?, ?, ?, ?)
                    """, (db_path, loc_id, tag, value))
                    conn.commit()
                    skipped_count += 1
                    continue

                try:
                    cursor.execute("""
                        INSERT INTO InputField (LocationId, TextTag, Value)
                        VALUES (?, ?, ?)
                    """, (mapped_loc, tag, value))
                    inserted_count += 1
                    print(f"‚úÖ Insert InputField : Loc={mapped_loc}, Tag={tag}")

                    # Enregistrer le mapping de cette ligne fusionn√©e
                    cursor.execute("""
                        INSERT INTO MergeMapping_InputField (SourceDb, OldLocationId, TextTag, Value)
                        VALUES (?, ?, ?, ?)
                    """, (db_path, loc_id, tag, value))
                    conn.commit()
                except Exception as e:
                    print(f"‚ùå Erreur insertion InputField (Loc={mapped_loc}, Tag={tag}): {e}")
    conn.close()

    print("\n=== STATISTIQUES INPUTFIELD ===")
    print(f"‚úÖ Lignes ins√©r√©es     : {inserted_count}")
    print(f"‚è© Doublons ignor√©s    : {skipped_count}")
    print(f"‚ùå LocationId manquants : {missing_count}")


def update_location_references(merged_db_path, location_replacements):
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    tables_with_single_location = [
        "InputField", "Note", "PlaylistItemLocationMap", "TagMap", "UserMark"
    ]

    for table in tables_with_single_location:
        for old_loc, new_loc in location_replacements.items():
            try:
                if table == "InputField":
                    # On g√®re ligne par ligne pour √©viter les doublons
                    cursor.execute("SELECT TextTag FROM InputField WHERE LocationId = ?", (old_loc,))
                    texttags = cursor.fetchall()
                    for (texttag,) in texttags:
                        cursor.execute("""
                            SELECT 1 FROM InputField WHERE LocationId = ? AND TextTag = ?
                        """, (new_loc, texttag))
                        if cursor.fetchone():
                            # Conflit d√©tect√©, on cherche un TextTag libre
                            base_tag = texttag
                            i = 1
                            new_tag = f"{base_tag}_{i}"
                            while True:
                                cursor.execute("""
                                    SELECT 1 FROM InputField WHERE LocationId = ? AND TextTag = ?
                                """, (new_loc, new_tag))
                                if not cursor.fetchone():
                                    break
                                i += 1
                                new_tag = f"{base_tag}_{i}"

                            # Met √† jour en modifiant le TextTag
                            cursor.execute("""
                                UPDATE InputField SET LocationId = ?, TextTag = ?
                                WHERE LocationId = ? AND TextTag = ?
                            """, (new_loc, new_tag, old_loc, base_tag))
                            print(
                                f"‚ö†Ô∏è Conflit √©vit√© : LocationId {old_loc} -> {new_loc}, TextTag={base_tag} devient {new_tag}")
                        cursor.execute("""
                            UPDATE InputField SET LocationId = ?
                            WHERE LocationId = ? AND TextTag = ?
                        """, (new_loc, old_loc, texttag))
                        print(f"InputField mis √† jour: LocationId {old_loc} -> {new_loc}, TextTag={texttag}")
                else:
                    cursor.execute(f"UPDATE {table} SET LocationId = ? WHERE LocationId = ?", (new_loc, old_loc))
                    print(f"{table} mis √† jour: LocationId {old_loc} -> {new_loc}")
            except Exception as e:
                print(f"Erreur mise √† jour {table} pour LocationId {old_loc}: {e}")

    # Mise √† jour s√©curis√©e pour Bookmark
    for old_loc, new_loc in location_replacements.items():
        try:
            cursor.execute("UPDATE Bookmark SET LocationId = ? WHERE LocationId = ?", (new_loc, old_loc))
            print(f"Bookmark LocationId mis √† jour: {old_loc} -> {new_loc}")
        except Exception as e:
            print(f"Erreur mise √† jour Bookmark LocationId {old_loc}: {e}")

        try:
            # S√©lection des lignes concern√©es par PublicationLocationId
            cursor.execute("""
                SELECT BookmarkId, Slot FROM Bookmark
                WHERE PublicationLocationId = ?
            """, (old_loc,))
            rows = cursor.fetchall()

            for bookmark_id, slot in rows:
                cursor.execute("""
                    SELECT 1 FROM Bookmark
                    WHERE PublicationLocationId = ? AND Slot = ? AND BookmarkId != ?
                """, (new_loc, slot, bookmark_id))
                conflict = cursor.fetchone()

                if conflict:
                    print(f"‚ö†Ô∏è Mise √† jour ignor√©e pour Bookmark ID {bookmark_id} (conflit avec PublicationLocationId={new_loc}, Slot={slot})")
                else:
                    cursor.execute("""
                        UPDATE Bookmark
                        SET PublicationLocationId = ?
                        WHERE BookmarkId = ?
                    """, (new_loc, bookmark_id))
                    print(f"Bookmark PublicationLocationId mis √† jour: {old_loc} -> {new_loc} (BookmarkId {bookmark_id})")

        except Exception as e:
            print(f"Erreur s√©curis√©e mise √† jour PublicationLocationId {old_loc}: {e}")

    conn.commit()
    try:
        conn.close()
        print("üîö Connexion ferm√©e dans update_location_references()")
    except Exception as e:
        print(f"‚ùå ERREUR lors de conn.close() : {e}")


def merge_usermark_from_sources(merged_db_path, file1_db, file2_db, location_id_map):
    """
    Fusionne la table UserMark des deux bases sources dans la DB fusionn√©e de fa√ßon idempotente.
    Pour chaque UserMark, un mapping (SourceDb, OldUserMarkId) -> NewUserMarkId est enregistr√© dans la table
    MergeMapping_UserMark afin d'√©viter les r√©insertion en doublon.
    Retourne un dictionnaire mapping de UserMark GUID vers le NewUserMarkId.
    """
    print("\n[FUSION USERMARK - ID√âMPOTENTE]")
    mapping = {}
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()
    # Cr√©e la table de mapping pour UserMark (si elle n'existe pas)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_UserMark (
            SourceDb TEXT,
            OldUserMarkId INTEGER,
            NewUserMarkId INTEGER,
            PRIMARY KEY (SourceDb, OldUserMarkId)
        )
    """)
    conn.commit()

    # R√©cup√®re le dernier ID dans la table UserMark de la DB fusionn√©e
    cursor.execute("SELECT COALESCE(MAX(UserMarkId), 0) FROM UserMark")
    max_id = cursor.fetchone()[0]

    # Traiter les deux fichiers source
    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version 
                FROM UserMark
            """)
            rows = src_cursor.fetchall()
            for old_um_id, color, loc_id, style, guid, version in rows:
                # V√©rifier si cet enregistrement a d√©j√† √©t√© trait√©
                cursor.execute("""
                    SELECT NewUserMarkId FROM MergeMapping_UserMark
                    WHERE SourceDb = ? AND OldUserMarkId = ?
                """, (db_path, old_um_id))
                res = cursor.fetchone()
                if res:
                    mapping[(db_path, old_um_id)] = res[0]
                    continue

                # Appliquer le mapping sur LocationId
                new_loc = location_id_map.get((db_path, loc_id), loc_id) if loc_id is not None else None

                # V√©rifier s'il existe d√©j√† un UserMark dans la DB fusionn√©e avec ce GUID
                cursor.execute("""
                    SELECT UserMarkId, ColorIndex, LocationId, StyleIndex, Version 
                    FROM UserMark 
                    WHERE UserMarkGuid = ?
                """, (guid,))
                existing = cursor.fetchone()
                if existing:
                    existing_id, ex_color, ex_loc, ex_style, ex_version = existing
                    # Si les donn√©es sont identiques, on peut r√©utiliser cet enregistrement
                    if (ex_color, ex_loc, ex_style, ex_version) == (color, new_loc, style, version):
                        new_um_id = existing_id
                    else:
                        # Conflit : on doit cr√©er un nouvel enregistrement
                        max_id += 1
                        new_um_id = max_id
                        cursor.execute("""
                            INSERT INTO UserMark (UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, (new_um_id, color, new_loc, style, guid, version))
                else:
                    max_id += 1
                    new_um_id = max_id
                    cursor.execute("""
                        INSERT INTO UserMark (UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (new_um_id, color, new_loc, style, guid, version))
                mapping[(db_path, old_um_id)] = new_um_id
                # Enregistrer le mapping dans la table d√©di√©e
                cursor.execute("""
                    INSERT INTO MergeMapping_UserMark (SourceDb, OldUserMarkId, NewUserMarkId)
                    VALUES (?, ?, ?)
                """, (db_path, old_um_id, new_um_id))
                conn.commit()
                # Pour faciliter l'usage en aval, on peut aussi construire un mapping par GUID
                mapping[guid] = new_um_id

    conn.close()
    print("Fusion UserMark termin√©e (idempotente).")
    return mapping


def insert_usermark_if_needed(conn, usermark_tuple):
    """
    usermark_tuple = (UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
    """
    (um_id, color, loc, style, guid, version) = usermark_tuple

    cur = conn.cursor()
    # V√©rifie si un usermark avec ce UserMarkGuid existe d√©j√†
    existing = cur.execute("SELECT UserMarkId, ColorIndex, LocationId, StyleIndex, Version FROM UserMark WHERE UserMarkGuid=?", (guid,)).fetchone()
    if existing:
        # Si la ligne est identique, on skip. Sinon, on peut d√©cider de faire un UPDATE
        (ex_id, ex_color, ex_loc, ex_style, ex_version) = existing
        if ex_color == color and ex_loc == loc and ex_style == style and ex_version == version:
            print(f"UserMarkGuid={guid} d√©j√† pr√©sent, identique, on skip l'insertion.")
            return
        else:
            print(f"UserMarkGuid={guid} existe d√©j√† avec des diff√©rences, on peut soit faire un UPDATE, soit g√©n√©rer un nouveau guid.")
            # Par exemple, on fait un UPDATE:
            cur.execute("""
                UPDATE UserMark
                SET ColorIndex=?, LocationId=?, StyleIndex=?, Version=?
                WHERE UserMarkGuid=?
            """, (color, loc, style, version, guid))
            return
    else:
        # Si pas trouv√©, on ins√®re
        try:
            cur.execute("""
                INSERT INTO UserMark (UserMarkId, ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (um_id, color, loc, style, guid, version))
        except Exception as e:
            print(f"Erreur insertion usermark {um_id} guid={guid}: {e}")


def merge_location_from_sources(merged_db_path, file1_db, file2_db):
    """
    Fusionne les enregistrements de la table Location depuis file1 et file2
    dans la base fusionn√©e de fa√ßon idempotente.
    Un mapping (SourceDb, OldID) -> NewID est persist√© dans une table d√©di√©e pour √©viter
    de r√©ins√©rer des entr√©es d√©j√† fusionn√©es.
    Retourne un dictionnaire de mapping.
    """
    def read_locations(db_path):
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        cur.execute("""
            SELECT LocationId, BookNumber, ChapterNumber, DocumentId, Track,
                   IssueTagNumber, KeySymbol, MepsLanguage, Type, Title
            FROM Location
        """)
        rows = cur.fetchall()
        conn.close()
        return [(db_path,) + row for row in rows]

    locations = read_locations(file1_db) + read_locations(file2_db)

    conn = sqlite3.connect(merged_db_path)
    cur = conn.cursor()

    # Cr√©er la table de mapping pour Location si elle n'existe pas
    cur.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_Location (
            SourceDb TEXT,
            OldID INTEGER,
            NewID INTEGER,
            PRIMARY KEY (SourceDb, OldID)
        )
    """)
    conn.commit()

    # R√©cup√©rer le dernier ID de Location d√©j√† pr√©sent dans la DB fusionn√©e
    cur.execute("SELECT MAX(LocationId) FROM Location")
    max_existing_id = cur.fetchone()[0]
    current_max_id = max_existing_id if max_existing_id is not None else 0

    location_id_map = {}

    for entry in locations:
        db_source = entry[0]
        old_loc_id, book_num, chap_num, doc_id, track, issue, key_sym, meps_lang, loc_type, title = entry[1:]

        # V√©rifier si ce Location a d√©j√† √©t√© fusionn√© depuis ce fichier source
        cur.execute("""
            SELECT NewID FROM MergeMapping_Location
            WHERE SourceDb = ? AND OldID = ?
        """, (db_source, old_loc_id))
        res = cur.fetchone()
        if res:
            new_id = res[0]
            print(f"‚è© Location d√©j√† fusionn√©e pour OldID {old_loc_id} depuis {db_source} -> NewID {new_id}")
            location_id_map[(db_source, old_loc_id)] = new_id
            continue

        # Chercher une correspondance d√©j√† existante dans la DB fusionn√©e
        found = False
        new_loc_id = None

        # Premi√®re contrainte UNIQUE pour publications classiques
        if None not in (book_num, chap_num, key_sym, meps_lang, loc_type):
            cur.execute("""
                SELECT LocationId FROM Location
                WHERE BookNumber = ? AND ChapterNumber = ? AND KeySymbol = ? AND MepsLanguage = ? AND Type = ?
            """, (book_num, chap_num, key_sym, meps_lang, loc_type))
            result = cur.fetchone()
            if result:
                found = True
                new_loc_id = result[0]

        # Sinon, v√©rification pour p√©riodiques
        if not found and None not in (key_sym, issue, meps_lang, doc_id, track, loc_type):
            cur.execute("""
                SELECT LocationId FROM Location
                WHERE KeySymbol = ? AND IssueTagNumber = ? AND MepsLanguage = ? AND DocumentId = ? AND Track = ? AND Type = ?
            """, (key_sym, issue, meps_lang, doc_id, track, loc_type))
            result = cur.fetchone()
            if result:
                found = True
                new_loc_id = result[0]

        if not found:
            # Aucune correspondance : on ins√®re une nouvelle ligne
            current_max_id += 1
            new_loc_id = current_max_id
            new_row = (
                new_loc_id, book_num, chap_num, doc_id, track, issue,
                key_sym, meps_lang, loc_type, title
            )
            try:
                cur.execute("""
                    INSERT INTO Location
                    (LocationId, BookNumber, ChapterNumber, DocumentId, Track, IssueTagNumber,
                     KeySymbol, MepsLanguage, Type, Title)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, new_row)
                print(f"Insertion Location depuis {db_source} : {new_row}")
            except sqlite3.IntegrityError as e:
                print(f"‚ö†Ô∏è Erreur insertion Location pour {new_row}: {e}")
                continue
        else:
            print(f"‚è© Location existante pour OldID {old_loc_id} depuis {db_source} -> NewID {new_loc_id}")

        location_id_map[(db_source, old_loc_id)] = new_loc_id

        # Enregistrer le mapping dans la table de mapping pour Location
        cur.execute("""
            INSERT INTO MergeMapping_Location (SourceDb, OldID, NewID)
            VALUES (?, ?, ?)
        """, (db_source, old_loc_id, new_loc_id))
        conn.commit()

    conn.close()
    return location_id_map


@app.route('/upload', methods=['GET', 'POST'])
def upload_files():
    if request.method == 'GET':
        response = jsonify({"message": "Route /upload fonctionne (GET) !"})
        response.headers.add("Access-Control-Allow-Origin", "*")
        return response, 200

    if 'file1' not in request.files or 'file2' not in request.files:
        return jsonify({"error": "Veuillez envoyer deux fichiers userData.db"}), 400

    file1 = request.files['file1']
    file2 = request.files['file2']

    # D√©finir les dossiers d'extraction (o√π sera plac√© chaque fichier userData.db)
    extracted1 = os.path.join("extracted", "file1_extracted")
    extracted2 = os.path.join("extracted", "file2_extracted")

    os.makedirs(extracted1, exist_ok=True)
    os.makedirs(extracted2, exist_ok=True)

    # Supprimer les anciens fichiers s'ils existent
    file1_path = os.path.join(extracted1, "userData.db")
    file2_path = os.path.join(extracted2, "userData.db")

    if os.path.exists(file1_path):
        os.remove(file1_path)
    if os.path.exists(file2_path):
        os.remove(file2_path)

    # Sauvegarde des fichiers userData.db
    file1.save(file1_path)
    file2.save(file2_path)

    response = jsonify({"message": "Fichiers userData.db re√ßus et enregistr√©s avec succ√®s !"})
    return response, 200


@app.route('/analyze', methods=['GET'])
def validate_db_path(db_path):
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"Database not found: {db_path}")


def analyze_files():
    try:
        file1_db = os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db")
        file2_db = os.path.join(EXTRACT_FOLDER, "file2_extracted", "userData.db")

        validate_db_path(file1_db)  # Validation ajout√©e
        validate_db_path(file2_db)  # Validation ajout√©e
        data1 = read_notes_and_highlights(file1_db)
        data2 = read_notes_and_highlights(file2_db)
        response = jsonify({"file1": data1, "file2": data2})
        response.headers.add("Access-Control-Allow-Origin", "*")

    except FileNotFoundError as e:
        return jsonify({"error": str(e)}), 404
    except Exception as e:
        app.logger.error(f"Analyze error: {str(e)}")
        return jsonify({"error": "Internal server error"}), 500


@app.route('/compare', methods=['GET'])
def compare_data():
    file1_db = os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db")
    file2_db = os.path.join(EXTRACT_FOLDER, "file2_extracted", "userData.db")
    data1 = read_notes_and_highlights(file1_db)
    data2 = read_notes_and_highlights(file2_db)
    notes1 = {note[1]: note[2] for note in data1.get("notes", [])}
    notes2 = {note[1]: note[2] for note in data2.get("notes", [])}
    identical_notes = {}
    conflicts_notes = {}
    unique_notes_file1 = {}
    unique_notes_file2 = {}
    for title in set(notes1.keys()).intersection(set(notes2.keys())):
        if notes1[title] == notes2[title]:
            identical_notes[title] = notes1[title]
        else:
            conflicts_notes[title] = {"file1": notes1[title], "file2": notes2[title]}
    for title in set(notes1.keys()).difference(set(notes2.keys())):
        unique_notes_file1[title] = notes1[title]
    for title in set(notes2.keys()).difference(set(notes1.keys())):
        unique_notes_file2[title] = notes2[title]
    highlights1 = {h[1]: h[2] for h in data1.get("highlights", [])}
    highlights2 = {h[1]: h[2] for h in data2.get("highlights", [])}
    identical_highlights = {}
    conflicts_highlights = {}
    unique_highlights_file1 = {}
    unique_highlights_file2 = {}
    for loc in set(highlights1.keys()).intersection(set(highlights2.keys())):
        if highlights1[loc] == highlights2[loc]:
            identical_highlights[loc] = highlights1[loc]
        else:
            conflicts_highlights[loc] = {"file1": highlights1[loc], "file2": highlights2[loc]}
    for loc in set(highlights1.keys()).difference(set(highlights2.keys())):
        unique_highlights_file1[loc] = highlights1[loc]
    for loc in set(highlights2.keys()).difference(set(highlights1.keys())):
        unique_highlights_file2[loc] = highlights2[loc]
    result = {
        "notes": {
            "identical": identical_notes,
            "conflicts": conflicts_notes,
            "unique_file1": unique_notes_file1,
            "unique_file2": unique_notes_file2
        },
        "highlights": {
            "identical": identical_highlights,
            "conflicts": conflicts_highlights,
            "unique_file1": unique_highlights_file1,
            "unique_file2": unique_highlights_file2
        }
    }
    return jsonify(result), 200


def merge_tags_and_tagmap(merged_db_path, file1_db, file2_db, note_mapping, location_id_map, playlist_item_id_map):
    """
    Fusionne les Tags et la table TagMap de fa√ßon idempotente.
    Pour chaque tag (sachant qu'un tag est identifi√© par (Type, Name)), on v√©rifie s'il existe d√©j√† dans la DB fusionn√©e.
    En cas d'insertion, le mapping (SourceDb, OldTagId) -> NewTagId est stock√© dans MergeMapping_Tag.
    De m√™me, pour chaque entr√©e TagMap, si des conflits de Position sont d√©tect√©s, la Position est incr√©ment√©e.
    Un mapping (SourceDb, OldTagMapId) -> NewTagMapId est enregistr√© dans MergeMapping_TagMap.
    Retourne deux mappings : tag_id_map et tagmap_id_map.
    """
    print("\n[FUSION TAGS ET TAGMAP - ID√âMPOTENT]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # Cr√©er les tables de mapping pour Tag et TagMap si elles n'existent pas
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_Tag (
            SourceDb TEXT,
            OldTagId INTEGER,
            NewTagId INTEGER,
            PRIMARY KEY (SourceDb, OldTagId)
        )
    """)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_TagMap (
            SourceDb TEXT,
            OldTagMapId INTEGER,
            NewTagMapId INTEGER,
            PRIMARY KEY (SourceDb, OldTagMapId)
        )
    """)
    conn.commit()

    # 1. Fusion des Tags
    cursor.execute("SELECT COALESCE(MAX(TagId), 0) FROM Tag")
    max_tag_id = cursor.fetchone()[0]

    tag_id_map = {}
    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("SELECT TagId, Type, Name FROM Tag")
            for tag_id, tag_type, tag_name in src_cursor.fetchall():
                # V√©rifier si ce tag a d√©j√† √©t√© fusionn√©
                cursor.execute("""
                    SELECT NewTagId FROM MergeMapping_Tag
                    WHERE SourceDb = ? AND OldTagId = ?
                """, (db_path, tag_id))
                res = cursor.fetchone()
                if res:
                    new_tag_id = res[0]
                    tag_id_map[(db_path, tag_id)] = new_tag_id
                    print(f"Tag d√©j√† fusionn√©: '{tag_name}' (OldTagId {tag_id}) -> NewTagId {new_tag_id}")
                    continue

                # Recherche d'un tag identique d√©j√† pr√©sent dans la DB fusionn√©e
                cursor.execute("SELECT TagId FROM Tag WHERE Type = ? AND Name = ?", (tag_type, tag_name))
                existing = cursor.fetchone()
                if existing:
                    new_tag_id = existing[0]
                    print(f"Tag existant trouv√©: '{tag_name}' (OldTagId {tag_id}) -> NewTagId {new_tag_id}")
                else:
                    max_tag_id += 1
                    new_tag_id = max_tag_id
                    cursor.execute("INSERT INTO Tag (TagId, Type, Name) VALUES (?, ?, ?)",
                                   (new_tag_id, tag_type, tag_name))
                    print(f"Insertion Tag: '{tag_name}' (OldTagId {tag_id}) -> NewTagId {new_tag_id}")

                tag_id_map[(db_path, tag_id)] = new_tag_id

                # Enregistrer le mapping pour ce tag
                cursor.execute("INSERT INTO MergeMapping_Tag (SourceDb, OldTagId, NewTagId) VALUES (?, ?, ?)",
                               (db_path, tag_id, new_tag_id))
                conn.commit()

    # 2. Fusion des TagMap
    cursor.execute("SELECT COALESCE(MAX(TagMapId), 0) FROM TagMap")
    max_tagmap_id = cursor.fetchone()[0]

    tagmap_id_map = {}
    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT TagMapId, PlaylistItemId, LocationId, NoteId, TagId, Position
                FROM TagMap
            """)
            for old_tagmap_id, playlist_item_id, location_id, note_id, old_tag_id, position in src_cursor.fetchall():
                # V√©rifier si cet enregistrement TagMap est d√©j√† fusionn√©
                cursor.execute("""
                    SELECT NewTagMapId FROM MergeMapping_TagMap
                    WHERE SourceDb = ? AND OldTagMapId = ?
                """, (db_path, old_tagmap_id))
                res = cursor.fetchone()
                if res:
                    tagmap_id_map[(db_path, old_tagmap_id)] = res[0]
                    print(f"TagMap d√©j√† fusionn√©: OldTagMapId {old_tagmap_id} -> NewTagMapId {res[0]}")
                    continue

                # Appliquer les mappings aux r√©f√©rences
                new_note_id = note_mapping.get((db_path, note_id)) if note_id else None
                norm_key = (os.path.normpath(db_path), location_id)
                normalized_map = {(os.path.normpath(k[0]), k[1]): v for k, v in location_id_map.items()}
                new_location_id = normalized_map.get(norm_key) if location_id else None
                new_playlist_item_id = playlist_item_id_map.get((db_path, playlist_item_id)) if playlist_item_id else None
                new_tag_id = tag_id_map.get((db_path, old_tag_id))

                # S'assurer qu'il y a au moins une r√©f√©rence parmi Note, Location ou PlaylistItem
                if all(v is None for v in [new_note_id, new_location_id, new_playlist_item_id]):
                    print(f"Aucune r√©f√©rence valide pour TagMap OldTagMapId {old_tagmap_id} (db: {db_path}), ignor√©e.")
                    continue

                # Ajuster la Position en cas de conflit pour ce Tag
                tentative = position
                while True:
                    cursor.execute("SELECT 1 FROM TagMap WHERE TagId = ? AND Position = ?", (new_tag_id, tentative))
                    if not cursor.fetchone():
                        break
                    print(f"Conflit sur TagMap pour TagId {new_tag_id} √† Position {tentative}. Incr√©mentation.")
                    tentative += 1

                max_tagmap_id += 1
                new_tagmap_id = max_tagmap_id
                try:
                    cursor.execute("""
                        INSERT INTO TagMap (TagMapId, PlaylistItemId, LocationId, NoteId, TagId, Position)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (new_tagmap_id, new_playlist_item_id, new_location_id, new_note_id, new_tag_id, tentative))
                    print(f"Insertion TagMap: OldTagMapId {old_tagmap_id} -> NewTagMapId {new_tagmap_id} avec Position {tentative}")
                except sqlite3.IntegrityError as e:
                    print(f"Erreur d'insertion TagMap pour OldTagMapId {old_tagmap_id}: {e}")
                    continue

                tagmap_id_map[(db_path, old_tagmap_id)] = new_tagmap_id
                cursor.execute("INSERT INTO MergeMapping_TagMap (SourceDb, OldTagMapId, NewTagMapId) VALUES (?, ?, ?)",
                               (db_path, old_tagmap_id, new_tagmap_id))
                conn.commit()

    conn.close()
    print("Fusion des Tags et TagMap termin√©e (idempotente).")
    return tag_id_map, tagmap_id_map


def merge_playlist_items(merged_db_path, file1_db, file2_db, im_mapping=None):
    """
    Fusionne la table PlaylistItem des deux bases sources dans la base fusionn√©e de fa√ßon idempotente.
    Pour chaque enregistrement, un mapping (SourceDb, OldItemId) -> NewItemId est enregistr√© dans la table
    MergeMapping_PlaylistItem afin d'√©viter de dupliquer les entr√©es lors d'ex√©cutions r√©p√©t√©es.
    En cas de doublon (d√©fini par une cl√© compos√©e des champs Label, StartTrimOffsetTicks, EndTrimOffsetTicks,
    Accuracy, EndAction et ThumbnailFilePath), la m√™me entr√©e est r√©utilis√©e.
    Retourne un mapping { (db_source, old_item_id): new_item_id }.
    """
    print("\n[FUSION PLAYLISTITEMS - ID√âMPOTENTE]")
    mapping = {}
    conn = sqlite3.connect(merged_db_path, timeout=30)
    conn.execute("PRAGMA busy_timeout = 10000")
    cursor = conn.cursor()

    # Cr√©er la table de mapping pour PlaylistItem si elle n'existe pas
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_PlaylistItem (
            SourceDb TEXT,
            OldItemId INTEGER,
            NewItemId INTEGER,
            PRIMARY KEY (SourceDb, OldItemId)
        )
    """)
    conn.commit()

    # V√©rifier que la table PlaylistItem existe dans la base fusionn√©e.
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='PlaylistItem'")
    if not cursor.fetchone():
        print("[ERREUR] La table PlaylistItem n'existe pas dans la DB fusionn√©e.")
        conn.close()
        return {}

    # Fonctions utilitaires pour normaliser les valeurs textuelles et num√©riques.
    def safe_text(val):
        return val if val is not None else ""

    def safe_number(val):
        return val if val is not None else 0

    # Dictionnaire pour d√©tecter les doublons dans la DB fusionn√©e, cl√© = (Label, StartTrim, EndTrim, Accuracy, EndAction, Thumbnail)
    existing_items = {}

    # Fonction pour lire les PlaylistItems d'une source.
    def read_playlist_items(db_path):
        with sqlite3.connect(db_path) as src_conn:
            cur_source = src_conn.cursor()
            cur_source.execute("""
                SELECT PlaylistItemId, Label, StartTrimOffsetTicks, EndTrimOffsetTicks, Accuracy, EndAction, ThumbnailFilePath
                FROM PlaylistItem
            """)
            rows = cur_source.fetchall()
        return [(db_path,) + row for row in rows]

    all_items = read_playlist_items(file1_db) + read_playlist_items(file2_db)
    print(f"Total playlist items lus : {len(all_items)}")

    # It√©ration sur tous les items des deux sources.
    for item in all_items:
        db_source = item[0]
        old_id, label, start_trim, end_trim, accuracy, end_action, thumb_path = item[1:]

        norm_label = safe_text(label)
        norm_start = safe_number(start_trim)
        norm_end = safe_number(end_trim)
        norm_thumb = safe_text(thumb_path)
        # D√©finir la cl√© de correspondance permettant de d√©tecter des doublons
        key = (norm_label, norm_start, norm_end, accuracy, end_action, norm_thumb)

        # V√©rifier si cet enregistrement a d√©j√† √©t√© trait√© en consultant la table de mapping
        cursor.execute("SELECT NewItemId FROM MergeMapping_PlaylistItem WHERE SourceDb = ? AND OldItemId = ?", (db_source, old_id))
        res = cursor.fetchone()
        if res:
            new_id = res[0]
            print(f"PlaylistItem d√©j√† fusionn√© pour OldID {old_id} de {db_source} -> NewID {new_id}")
            mapping[(db_source, old_id)] = new_id
            # Enregistrement dans existing_items s'il n'est pas d√©j√† pr√©sent.
            if key not in existing_items:
                existing_items[key] = new_id
            continue

        if key in existing_items:
            # Doublon d√©tect√© : on r√©utilise le NewItemId d√©j√† ins√©r√©.
            new_id = existing_items[key]
            print(f"Doublon d√©tect√© pour key {key}. R√©utilisation de l'ID {new_id} pour OldID {old_id} de {db_source}.")
        else:
            try:
                cursor.execute("""
                    INSERT INTO PlaylistItem 
                    (Label, StartTrimOffsetTicks, EndTrimOffsetTicks, Accuracy, EndAction, ThumbnailFilePath)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (label, start_trim, end_trim, accuracy, end_action, thumb_path))
                new_id = cursor.lastrowid
                print(f"Insertion r√©ussie avec nouvel ID {new_id} pour '{label}' (OldID {old_id} de {db_source})")
                existing_items[key] = new_id
            except sqlite3.IntegrityError as e:
                print(f"Erreur insertion PlaylistItem OldID {old_id} de {db_source}: {e}")
                continue

        # Enregistrer le mapping pour cet enregistrement.
        cursor.execute("""
            INSERT INTO MergeMapping_PlaylistItem (SourceDb, OldItemId, NewItemId)
            VALUES (?, ?, ?)
        """, (db_source, old_id, new_id))
        conn.commit()
        mapping[(db_source, old_id)] = new_id

    print(f"Total items mapp√©s: {len(mapping)}")
    conn.close()
    return mapping


def merge_playlist_item_accuracy(merged_db_path, file1_db, file2_db):
    """
    Fusionne la table PlaylistItemAccuracy de fa√ßon idempotente.
    Utilise INSERT OR IGNORE car cette table est simple.
    Retourne l'ID max final.
    """
    print("\n[FUSION PLAYLISTITEMACCURACY]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    cursor.execute("SELECT COALESCE(MAX(PlaylistItemAccuracyId), 0) FROM PlaylistItemAccuracy")
    max_acc_id = cursor.fetchone()[0] or 0
    print(f"ID max initial: {max_acc_id}")

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("SELECT * FROM PlaylistItemAccuracy")
            records = src_cursor.fetchall()
            print(f"{len(records)} records trouv√©s dans {os.path.basename(db_path)}")
            for acc_id, desc in records:
                try:
                    cursor.execute("INSERT OR IGNORE INTO PlaylistItemAccuracy VALUES (?, ?)", (acc_id, desc))
                    max_acc_id = max(max_acc_id, acc_id)
                except sqlite3.IntegrityError:
                    print(f"Duplicate PlaylistItemAccuracy: {acc_id} (ignor√©)")
    conn.commit()
    conn.close()
    print(f"ID max final: {max_acc_id}")
    return max_acc_id


def merge_playlist_item_location_map(merged_db_path, file1_db, file2_db, item_id_map, location_id_map):
    """
    Fusionne la table PlaylistItemLocationMap de fa√ßon idempotente en appliquant
    le mapping des PlaylistItems et des Locations.
    """
    print("\n[FUSION PLAYLISTITEMLOCATIONMAP]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT PlaylistItemId, LocationId, MajorMultimediaType, BaseDurationTicks
                FROM PlaylistItemLocationMap
            """)
            mappings = src_cursor.fetchall()
            print(f"{len(mappings)} mappings trouv√©s dans {os.path.basename(db_path)}")
            for old_item_id, old_loc_id, mm_type, duration in mappings:
                new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                new_loc_id = location_id_map.get((db_path, old_loc_id))
                if new_item_id and new_loc_id:
                    try:
                        cursor.execute("""
                            INSERT OR IGNORE INTO PlaylistItemLocationMap
                            VALUES (?, ?, ?, ?)
                        """, (new_item_id, new_loc_id, mm_type, duration))
                    except sqlite3.IntegrityError as e:
                        print(f"Erreur PlaylistItemLocationMap: {e}")
                else:
                    print(
                        f"‚ö†Ô∏è Mapping manquant pour PlaylistItemId={old_item_id}, LocationId={old_loc_id} (db: {db_path})")
    conn.commit()
    conn.close()


def merge_playlist_item_media_map(merged_db_path, file1_db, file2_db, item_id_map, independent_media_map):
    """
    Fusionne la table PlaylistItemIndependentMediaMap des deux sources dans
    PlaylistItemMediaMap de la DB fusionn√©e de fa√ßon idempotente.
    Utilise DurationTicks de la source pour remplir OrderIndex dans la cible.
    """
    print("\n[FUSION PLAYLISTITEMMEDIA MAP]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT PlaylistItemId, IndependentMediaId, DurationTicks
                FROM PlaylistItemIndependentMediaMap
            """)
            rows = src_cursor.fetchall()
            print(f"{len(rows)} lignes trouv√©es dans {os.path.basename(db_path)}")

            for old_item_id, old_media_id, duration_ticks in rows:
                new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                new_media_id = independent_media_map.get((db_path, old_media_id))
                order_idx = duration_ticks  # on r√©utilise DurationTicks comme OrderIndex

                if new_item_id and new_media_id:
                    try:
                        cursor.execute("""
                            INSERT OR IGNORE INTO PlaylistItemMediaMap
                            (PlaylistItemId, MediaFileId, OrderIndex)
                            VALUES (?, ?, ?)
                        """, (new_item_id, new_media_id, order_idx))
                    except sqlite3.IntegrityError as e:
                        print(f"Erreur PlaylistItemMediaMap: {e}")
                else:
                    print(
                        f"‚ö†Ô∏è Mapping manquant pour PlaylistItemId={old_item_id}, "
                        f"IndependentMediaId={old_media_id} (db: {db_path})"
                    )

    conn.commit()
    conn.close()


def merge_playlist_item_marker(merged_db_path, file1_db, file2_db, item_id_map):
    """
    Fusionne la table PlaylistItemMarker de fa√ßon idempotente.
    Utilise une table de mapping MergeMapping_PlaylistItemMarker pour √©viter de r√©ins√©rer
    des markers d√©j√† fusionn√©s. Retourne marker_id_map.
    """
    print("\n[FUSION PLAYLISTITEMMARKER]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # Cr√©er la table de mapping pour PlaylistItemMarker si elle n'existe pas
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_PlaylistItemMarker (
            SourceDb TEXT,
            OldMarkerId INTEGER,
            NewMarkerId INTEGER,
            PRIMARY KEY (SourceDb, OldMarkerId)
        )
    """)
    conn.commit()

    cursor.execute("SELECT COALESCE(MAX(PlaylistItemMarkerId), 0) FROM PlaylistItemMarker")
    max_marker_id = cursor.fetchone()[0] or 0
    print(f"ID max initial: {max_marker_id}")
    marker_id_map = {}

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as src_conn:
            src_cursor = src_conn.cursor()
            src_cursor.execute("""
                SELECT PlaylistItemMarkerId, PlaylistItemId, Label, StartTimeTicks, DurationTicks, EndTransitionDurationTicks
                FROM PlaylistItemMarker
            """)
            markers = src_cursor.fetchall()
            print(f"{len(markers)} markers trouv√©s dans {os.path.basename(db_path)}")
            for old_marker_id, old_item_id, label, start_time, duration, end_transition in markers:
                new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                if not new_item_id:
                    print(f"    > ID item introuvable pour marker {old_marker_id} ‚Äî ignor√©")
                    continue
                # V√©rifier dans le mapping persistant
                cursor.execute("""
                    SELECT NewMarkerId FROM MergeMapping_PlaylistItemMarker
                    WHERE SourceDb = ? AND OldMarkerId = ?
                """, (db_path, old_marker_id))
                res = cursor.fetchone()
                if res:
                    marker_id_map[(db_path, old_marker_id)] = res[0]
                    continue
                max_marker_id += 1
                new_row = (max_marker_id, new_item_id, label, start_time, duration, end_transition)
                try:
                    cursor.execute("""
                        INSERT INTO PlaylistItemMarker
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, new_row)
                    marker_id_map[(db_path, old_marker_id)] = max_marker_id
                    cursor.execute("""
                        INSERT INTO MergeMapping_PlaylistItemMarker (SourceDb, OldMarkerId, NewMarkerId)
                        VALUES (?, ?, ?)
                    """, (db_path, old_marker_id, max_marker_id))
                    conn.commit()
                except sqlite3.IntegrityError as e:
                    print(f"Erreur insertion PlaylistItemMarker pour OldMarkerId {old_marker_id}: {e}")
    print(f"ID max final: {max_marker_id}")
    print(f"Total markers mapp√©s: {len(marker_id_map)}")
    conn.close()
    return marker_id_map


def merge_marker_maps(merged_db_path, file1_db, file2_db, marker_id_map):
    """
    Fusionne les tables de mapping li√©es aux markers, y compris PlaylistItemMarkerMap
    et les MarkerMaps sp√©cifiques (BibleVerse et Paragraph).
    """
    print("\n[FUSION MARKER MAPS]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()

    # 5.2. Fusion des MarkerMaps sp√©cifiques
    for map_type in ['BibleVerse', 'Paragraph']:
        table_name = f'PlaylistItemMarker{map_type}Map'
        cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'")
        if not cursor.fetchone():
            print(f"Table {table_name} non trouv√©e - ignor√©e")
            continue
        print(f"\nFusion de {table_name}")
        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cursor = src_conn.cursor()
                src_cursor.execute(f"SELECT * FROM {table_name}")
                rows = src_cursor.fetchall()
                print(f"{len(rows)} entr√©es trouv√©es dans {os.path.basename(db_path)} pour {table_name}")
                for row in rows:
                    old_marker_id = row[0]
                    new_marker_id = marker_id_map.get((db_path, old_marker_id))
                    if not new_marker_id:
                        continue
                    new_row = (new_marker_id,) + row[1:]
                    placeholders = ",".join(["?"] * len(new_row))
                    try:
                        cursor.execute(f"INSERT OR IGNORE INTO {table_name} VALUES ({placeholders})", new_row)
                    except sqlite3.IntegrityError as e:
                        print(f"Erreur dans {table_name}: {e}")
    conn.commit()
    conn.close()


def merge_playlist_final(merged_db_path, file1_db, file2_db):
    """
    Fusionne la table Playlist finale de fa√ßon idempotente.
    G√®re les conflits sur le nom en ajoutant un suffixe pour garantir l'unicit√©.
    Utilise la table de mapping MergeMapping_Playlist pour √©viter la r√©insertion.
    Retourne un mapping { (SourceDb, OldPlaylistId) : NewPlaylistId }.
    """
    print("\n[FUSION PLAYLIST FINAL - ID√âMPOTENTE]")
    conn = sqlite3.connect(merged_db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='Playlist'")
    if not cursor.fetchone():
        print("üö´ Table 'Playlist' absente ‚Äî √©tape ignor√©e.")
        conn.close()
        return {}

    cursor.execute("""
        CREATE TABLE IF NOT EXISTS MergeMapping_Playlist (
            SourceDb TEXT,
            OldPlaylistId INTEGER,
            NewPlaylistId INTEGER,
            PRIMARY KEY (SourceDb, OldPlaylistId)
        )
    """)
    conn.commit()
    cursor.execute("SELECT COALESCE(MAX(PlaylistId), 0) FROM Playlist")
    max_playlist_id = cursor.fetchone()[0] or 0
    playlist_id_map = {}

    for db_path in [file1_db, file2_db]:
        with sqlite3.connect(db_path) as source_conn:
            source_cursor = source_conn.cursor()
            source_cursor.execute("""
                SELECT PlaylistId, Name, Description, IconId, OrderIndex, LastModified
                FROM Playlist
            """)
            playlists = source_cursor.fetchall()
            print(f"{len(playlists)} playlists trouv√©es dans {os.path.basename(db_path)}")
            for pl_id, name, desc, icon, order_idx, modified in playlists:
                # V√©rifier si cet enregistrement est d√©j√† fusionn√©
                cursor.execute("""
                    SELECT NewPlaylistId FROM MergeMapping_Playlist
                    WHERE SourceDb = ? AND OldPlaylistId = ?
                """, (db_path, pl_id))
                res = cursor.fetchone()
                if res:
                    new_id = res[0]
                    playlist_id_map[(db_path, pl_id)] = new_id
                    print(f"Playlist d√©j√† fusionn√©e : OldID {pl_id} -> NewID {new_id}")
                    continue
                original_name = name
                suffix = 1
                while True:
                    cursor.execute("SELECT 1 FROM Playlist WHERE Name = ?", (name,))
                    if not cursor.fetchone():
                        break
                    name = f"{original_name} ({suffix})"
                    suffix += 1
                max_playlist_id += 1
                try:
                    cursor.execute("""
                        INSERT INTO Playlist
                        (PlaylistId, Name, Description, IconId, OrderIndex, LastModified)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (max_playlist_id, name, desc, icon, order_idx, modified))
                    playlist_id_map[(db_path, pl_id)] = max_playlist_id
                    print(f"Insertion Playlist : OldID {pl_id} -> NewID {max_playlist_id} avec nom '{name}'")
                except sqlite3.IntegrityError as e:
                    print(f"ERREUR Playlist {pl_id} de {db_path}: {str(e)}")
                    continue
                cursor.execute("""
                    INSERT INTO MergeMapping_Playlist (SourceDb, OldPlaylistId, NewPlaylistId)
                    VALUES (?, ?, ?)
                """, (db_path, pl_id, max_playlist_id))
                conn.commit()
    conn.close()
    return playlist_id_map


def merge_playlists(merged_db_path, file1_db, file2_db, location_id_map, independent_media_map, item_id_map):
    """Fusionne toutes les tables li√©es aux playlists en respectant les contraintes."""
    print("\n=== D√âBUT FUSION PLAYLISTS ===")

    max_media_id = 0  # üîß Ajout essentiel
    max_playlist_id = 0  # üîß pour √©viter 'not associated with a value'
    conn = None  # üß∑ Pour pouvoir le fermer plus tard

    try:
        conn = sqlite3.connect(merged_db_path, timeout=30)
        conn.execute("PRAGMA busy_timeout = 10000")
        cursor = conn.cursor()

        print("\n[INITIALISATION]")
        print(f"Base de fusion: {merged_db_path}")
        print(f"Source 1: {file1_db}")
        print(f"Source 2: {file2_db}")
        print(f"Location IDs mapp√©s: {len(location_id_map)}")

        item_id_map = merge_playlist_items(
            merged_db_path, file1_db, file2_db, independent_media_map  # ‚úÖ 4 max
        )

        # Appel imm√©diat √† merge_playlist_items pour avoir item_id_map dispo d√®s le d√©but
        print(f"Mapping PlaylistItems: {item_id_map}")

        # ... (la suite continue normalement)

        marker_id_map = {}

        # 1. Fusion PlaylistItemAccuracy
        print("\n[FUSION PLAYLISTITEMACCURACY]")
        cursor.execute("SELECT MAX(PlaylistItemAccuracyId) FROM PlaylistItemAccuracy")
        max_acc_id = cursor.fetchone()[0] or 0
        print(f"ID max initial: {max_acc_id}")

        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cur = src_conn.cursor()
                src_cur.execute("SELECT * FROM PlaylistItemAccuracy")
                records = src_cur.fetchall()
                print(f"{len(records)} records trouv√©s dans {os.path.basename(db_path)}")
                for acc_id, desc in records:
                    try:
                        cursor.execute("INSERT OR IGNORE INTO PlaylistItemAccuracy VALUES (?, ?)", (acc_id, desc))
                        max_acc_id = max(max_acc_id, acc_id)
                    except sqlite3.IntegrityError:
                        print(f"Duplicate PlaylistItemAccuracy: {acc_id} (ignor√©)")
        print(f"ID max final: {max_acc_id}")

        # 2. Fusion PlaylistItemLocationMap
        print("\n[FUSION PLAYLISTITEMLOCATIONMAP]")
        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cur = src_conn.cursor()
                src_cur.execute("""
                    SELECT PlaylistItemId, LocationId, MajorMultimediaType, BaseDurationTicks
                    FROM PlaylistItemLocationMap
                """)
                mappings = src_cur.fetchall()
                print(f"{len(mappings)} mappings trouv√©s dans {os.path.basename(db_path)}")
                for old_item_id, old_loc_id, mm_type, duration in mappings:
                    new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                    new_loc_id = location_id_map.get((db_path, old_loc_id))
                    if new_item_id and new_loc_id:
                        try:
                            cursor.execute("""
                                INSERT OR IGNORE INTO PlaylistItemLocationMap
                                VALUES (?, ?, ?, ?)
                            """, (new_item_id, new_loc_id, mm_type, duration))
                        except sqlite3.IntegrityError as e:
                            print(f"Erreur PlaylistItemLocationMap: {e}")
                        else:
                            print(
                                f"‚ö†Ô∏è Mapping manquant : ItemId={old_item_id}, LocationId={old_loc_id} (dans {os.path.basename(db_path)})")

        # 3. Fusion PlaylistItemMediaMap
        print("\n[FUSION PlaylistItemMediaMap]")
        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cur = src_conn.cursor()

                # V√©rifie si la table existe avant de tenter un SELECT
                src_cur.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name='PlaylistItemMediaMap'
                """)
                if not src_cur.fetchone():
                    print(f"‚è≠Ô∏è Table PlaylistItemMediaMap absente dans {os.path.basename(db_path)}, √©tape ignor√©e.")
                    continue

                src_cur.execute("""
                    SELECT PlaylistItemId, MediaFileId, OrderIndex
                    FROM PlaylistItemMediaMap
                """)
                rows = src_cur.fetchall()
                print(f"{len(rows)} lignes trouv√©es dans {os.path.basename(db_path)}")

                for old_item_id, old_media_id, order_idx in rows:
                    print(
                        f"Mapping demand√© pour ({db_path}, {old_item_id}) ‚Üí {item_id_map.get((db_path, old_item_id))}")
                    new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                    new_media_id = independent_media_map.get((db_path, old_media_id))

                    if new_item_id and new_media_id:
                        try:
                            cursor.execute("""
                                INSERT OR IGNORE INTO PlaylistItemMediaMap
                                (PlaylistItemId, MediaFileId, OrderIndex)
                                VALUES (?, ?, ?)
                            """, (new_item_id, new_media_id, order_idx))
                        except sqlite3.IntegrityError as e:
                            print(f"Erreur PlaylistItemMediaMap: {e}")
                    else:
                        print(
                            f"‚ö†Ô∏è Mapping manquant pour PlaylistItemId={old_item_id}, MediaFileId={old_media_id} (db: {db_path})")

        # 4. Fusion PlaylistItemMarker
        print("\n[FUSION PLAYLISTITEMMARKER]")
        cursor.execute("SELECT MAX(PlaylistItemMarkerId) FROM PlaylistItemMarker")
        max_marker_id = cursor.fetchone()[0] or 0
        print(f"ID max initial: {max_marker_id}")

        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cur = src_conn.cursor()
                src_cur.execute("""
                    SELECT PlaylistItemMarkerId, PlaylistItemId, Label, 
                           StartTimeTicks, DurationTicks, EndTransitionDurationTicks
                    FROM PlaylistItemMarker
                """)
                markers = src_cur.fetchall()
                print(f"{len(markers)} markers trouv√©s dans {os.path.basename(db_path)}")
                for row in markers:
                    old_marker_id = row[0]
                    old_item_id = row[1]
                    new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))

                    if new_item_id is None:
                        print(f"    > ID item introuvable pour marker {old_marker_id} ‚Äî ignor√©")
                        continue

                    max_marker_id += 1
                    new_row = (max_marker_id, new_item_id) + row[2:]

                    try:
                        cursor.execute("""
                            INSERT INTO PlaylistItemMarker
                            VALUES (?, ?, ?, ?, ?, ?)
                        """, new_row)
                        marker_id_map[(db_path, old_marker_id)] = max_marker_id
                    except sqlite3.IntegrityError as e:
                        print(f"Erreur insertion PlaylistItemMarker: {e}")

        print(f"ID max final: {max_marker_id}")
        print(f"Total markers mapp√©s: {len(marker_id_map)}")

        # 5. Fusion des PlaylistItemMarkerMap et Marker*Map (BibleVerse/Paragraph)
        print("\n[FUSION MARKER MAPS]")

        # 5.1 Fusion PlaylistItemMarkerMap (si elle existe)
        print("\n[FUSION PlaylistItemMarkerMap]")
        for db_path in [file1_db, file2_db]:
            with sqlite3.connect(db_path) as src_conn:
                src_cur = src_conn.cursor()

                # V√©rifie l'existence de la table
                src_cur.execute("""
                    SELECT name FROM sqlite_master
                    WHERE type='table' AND name='PlaylistItemMarkerMap'
                """)
                if not src_cur.fetchone():
                    print(f"‚è≠Ô∏è Table PlaylistItemMarkerMap absente dans {os.path.basename(db_path)}, √©tape ignor√©e.")
                    continue

                src_cur.execute("""
                    SELECT PlaylistItemId, MarkerId
                    FROM PlaylistItemMarkerMap
                """)
                rows = src_cur.fetchall()
                print(f"{len(rows)} lignes trouv√©es dans {os.path.basename(db_path)}")

                for old_item_id, old_marker_id in rows:
                    new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                    new_marker_id = marker_id_map.get((db_path, old_marker_id))

                    if new_item_id and new_marker_id:
                        try:
                            cursor.execute("""
                                INSERT OR IGNORE INTO PlaylistItemMarkerMap
                                (PlaylistItemId, MarkerId)
                                VALUES (?, ?)
                            """, (new_item_id, new_marker_id))
                        except sqlite3.IntegrityError as e:
                            print(f"Erreur PlaylistItemMarkerMap: {e}")
                    else:
                        print(f"‚ö†Ô∏è Mapping manquant pour item {old_item_id} ou marker {old_marker_id} dans {db_path}")

        # 5.2. Fusion des PlaylistItemMarkerBibleVerseMap et ParagraphMap
        for map_type in ['BibleVerse', 'Paragraph']:
            table_name = f'PlaylistItemMarker{map_type}Map'
            if not cursor.execute(
                    f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}'"
            ).fetchone():
                print(f"Table {table_name} non trouv√©e - ignor√©e")
                continue
            print(f"\nFusion {table_name}")
            for db_path in [file1_db, file2_db]:
                with sqlite3.connect(db_path) as source_conn:
                    source_cursor = source_conn.cursor()
                    source_cursor.execute(f"SELECT * FROM {table_name}")
                    maps = source_cursor.fetchall()
                    print(f"{len(maps)} entries dans {os.path.basename(db_path)}")
                    for row in maps:
                        old_marker_id = row[0]
                        new_marker_id = marker_id_map.get((db_path, old_marker_id))
                        if new_marker_id:
                            new_row = (new_marker_id,) + row[1:]
                            try:
                                placeholders = ",".join(["?"] * len(new_row))
                                cursor.execute(f"INSERT OR IGNORE INTO {table_name} VALUES ({placeholders})", new_row)
                            except sqlite3.IntegrityError as e:
                                print(f"Erreur {table_name}: {e}")

        # 6. Fusion de PlaylistItemIndependentMediaMap
        print("\n[FUSION INDEPENDENTMEDIAMAP]")
        if cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='PlaylistItemIndependentMediaMap'"
        ).fetchone():
            for db_path in [file1_db, file2_db]:
                with sqlite3.connect(db_path) as source_conn:
                    source_cursor = source_conn.cursor()
                    source_cursor.execute("""
                        SELECT PlaylistItemId, IndependentMediaId, DurationTicks
                        FROM PlaylistItemIndependentMediaMap
                    """)
                    media_maps = source_cursor.fetchall()
                    print(f"{len(media_maps)} entries dans {os.path.basename(db_path)}")
                    for old_item_id, old_media_id, duration in media_maps:
                        new_item_id = item_id_map.get((os.path.normpath(db_path), old_item_id))
                        new_media_id = independent_media_map.get((db_path, old_media_id))
                        if new_item_id and new_media_id:
                            try:
                                cursor.execute("""
                                    INSERT OR IGNORE INTO PlaylistItemIndependentMediaMap
                                    VALUES (?, ?, ?)
                                """, (new_item_id, new_media_id, duration))
                            except sqlite3.IntegrityError as e:
                                print(f"Erreur IndependentMediaMap: {e}")
                        else:
                            print(
                                f"  ‚ö†Ô∏è Mapping manquant pour Item={old_item_id}, Media={old_media_id} (db: {db_path})")
        else:
            print("Table PlaylistItemIndependentMediaMap non trouv√©e - ignor√©e")

        # ========================
        # Maintenant, on d√©marre les op√©rations qui ouvrent leurs propres connexions
        # ========================

        # 7. Fusion de la table IndependentMedia (am√©lior√©e)
        print("\n[FUSION INDEPENDENTMEDIA]")
        # On r√©utilise le mapping d√©j√† pr√©par√© dans merge_data
        im_mapping = independent_media_map

        # 8. V√©rification finale des thumbnails
        print("\n[V√âRIFICATION THUMBNAILS ORPHELINS]")
        cursor.execute("""
            SELECT p.PlaylistItemId, p.ThumbnailFilePath
            FROM PlaylistItem p
            WHERE p.ThumbnailFilePath IS NOT NULL
              AND NOT EXISTS (
                  SELECT 1 FROM IndependentMedia m 
                  WHERE m.FilePath = p.ThumbnailFilePath
              )
        """)
        orphaned_thumbnails = cursor.fetchall()
        if orphaned_thumbnails:
            print(f"Avertissement : {len(orphaned_thumbnails)} thumbnails sans m√©dia associ√©")

            # ‚úÖ Ajoute ceci ici (pas en dehors)
            conn.commit()

        # 9. Finalisation playlists
        print("\n=== FUSION PLAYLISTS TERMIN√âE ===")
        playlist_results = {
            'item_id_map': item_id_map,
            'marker_id_map': marker_id_map,
            'media_status': {
                'total_media': max_media_id,
                'orphaned_thumbnails': len(orphaned_thumbnails) if 'orphaned_thumbnails' in locals() else 0
            }
        }
        print(f"R√©sum√© interm√©diaire: {playlist_results}")

        # 10. (Optionnel) Fusion de la table Playlist si elle existe
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='Playlist'")
        has_playlist_table = cursor.fetchone() is not None

        if not has_playlist_table:
            print("üö´ Table 'Playlist' absente ‚Äî √©tape ignor√©e.")
        else:
            print("\n=== D√âBUT FUSION PLAYLIST ===")
            cursor.execute("SELECT MAX(PlaylistId) FROM Playlist")
            max_playlist_id = cursor.fetchone()[0] or 0
            print(f"ID max initial Playlist: {max_playlist_id}")
            playlist_id_map = {}

            for db_path in [file1_db, file2_db]:
                with sqlite3.connect(db_path) as source_conn:
                    source_cursor = source_conn.cursor()
                    source_cursor.execute("""
                        SELECT PlaylistId, Name, Description, IconId, OrderIndex, LastModified
                        FROM Playlist
                    """)
                    playlists = source_cursor.fetchall()
                    print(f"{len(playlists)} playlists trouv√©es dans {os.path.basename(db_path)}")

                    for pl_id, name, desc, icon, order_idx, modified in playlists:
                        original_name = name
                        suffix = 1
                        while True:
                            cursor.execute("SELECT 1 FROM Playlist WHERE Name = ?", (name,))
                            if not cursor.fetchone():
                                break
                            name = f"{original_name} ({suffix})"
                            suffix += 1

                        max_playlist_id += 1
                        try:
                            cursor.execute("""
                                INSERT INTO Playlist
                                (PlaylistId, Name, Description, IconId, OrderIndex, LastModified)
                                VALUES (?, ?, ?, ?, ?, ?)
                            """, (max_playlist_id, name, desc, icon, order_idx, modified))
                            playlist_id_map[(db_path, pl_id)] = max_playlist_id
                        except sqlite3.IntegrityError as e:
                            print(f"ERREUR Playlist {pl_id}: {str(e)}")

            print(f"Playlist fusionn√©e - ID max final: {max_playlist_id}")
            print(f"Total playlists fusionn√©es: {len(playlist_id_map)}")

        # 12. Optimisations finales (d√©sactiv√© pour PlaylistItem)
        print("\n=== DEBUT OPTIMISATIONS ===")
        print("Aucun nettoyage n'est effectu√© sur PlaylistItem.")
        orphaned_deleted = 0

        # Journalisation d√©taill√©e
        log_file = os.path.join(UPLOAD_FOLDER, "fusion.log")
        print(f"\nCr√©ation fichier log: {log_file}")
        with open(log_file, "a") as f:
            f.write(f"\n\n=== Session {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")

        def log_message(message, log_type="INFO"):
            print(message)
            with open(log_file, "a") as f:
                f.write(f"[{log_type}] {datetime.now().strftime('%H:%M:%S')} - {message}\n")

        # 13.1 Reconstruction des index
        print("\nReconstruction des index...")
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
        indexes = [row[0] for row in cursor.fetchall() if not row[0].startswith('sqlite_autoindex_')]
        for index_name in indexes:
            try:
                cursor.execute(f"REINDEX {index_name}")
                log_message(f"Index reconstruit: {index_name}")
            except sqlite3.Error as e:
                log_message(f"ERREUR sur index {index_name}: {str(e)}", "ERROR")

        # 13.2 V√©rification int√©grit√©
        print("\nV√©rification int√©grit√© base de donn√©es...")
        cursor.execute("PRAGMA quick_check")
        integrity_result = cursor.fetchone()[0]
        if integrity_result == "ok":
            log_message("Int√©grit√© de la base: OK")
        else:
            log_message(f"ERREUR int√©grit√©: {integrity_result}", "ERROR")

        # 13.3 V√©rification cl√©s √©trang√®res
        cursor.execute("PRAGMA foreign_key_check")
        fk_issues = cursor.fetchall()
        if fk_issues:
            log_message(f"ATTENTION: {len(fk_issues)} probl√®mes de cl√©s √©trang√®res", "WARNING")
            for issue in fk_issues[:3]:
                log_message(f"- Probl√®me: {issue}", "WARNING")
        else:
            log_message("Aucun probl√®me de cl√© √©trang√®re d√©tect√©")

        # 13.4 Optimisation finale
        print("\nOptimisation finale...")
        conn.commit()  # S'assurer de cl√¥turer la transaction en cours
        start_time = time.perf_counter()
        cursor.execute("VACUUM")
        cursor.execute("PRAGMA optimize")
        optimization_time = time.perf_counter() - start_time
        log_message(f"Optimisation termin√©e en {optimization_time:.2f}s")

        # 14. Finalisation
        # commit final et fermeture propre
        conn.commit()

        # R√©capitulatif final
        print("\n=== R√âCAPITULATIF FINAL ===")
        print(f"{'Playlists:':<20} {max_playlist_id}")
        print(f"{'√âl√©ments:':<20} {len(item_id_map)}")
        print(f"{'M√©dias:':<20} {max_media_id}")
        print(f"{'Nettoy√©s:':<20} {orphaned_deleted}")
        print(f"{'Int√©grit√©:':<20} {integrity_result}")
        if fk_issues:
            print(f"{'Probl√®mes FK:':<20} \033[91m{len(fk_issues)}\033[0m")
        else:
            print(f"{'Probl√®mes FK:':<20} \033[92mAucun\033[0m")
        with sqlite3.connect(merged_db_path) as test_conn:
            test_cursor = test_conn.cursor()
            test_cursor.execute("SELECT 1 FROM sqlite_master LIMIT 1")
            db_status = "OK" if test_cursor.fetchone() else "ERREUR"
            print(f"\nStatut final DB: {db_status}")

        # 16. Activation WAL
        conn = sqlite3.connect(merged_db_path)
        cursor = conn.cursor()
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("CREATE TABLE IF NOT EXISTS dummy_for_wal (id INTEGER PRIMARY KEY)")
        cursor.execute("INSERT INTO dummy_for_wal DEFAULT VALUES")
        conn.commit()
        cursor.execute("DELETE FROM dummy_for_wal")
        conn.commit()
        cursor.execute("DROP TABLE dummy_for_wal")
        conn.commit()
        conn.close()

        with sqlite3.connect(merged_db_path) as test_conn:
            new_wal_status = test_conn.execute("PRAGMA journal_mode").fetchone()[0]
            print(f"Statut WAL apr√®s activation: {new_wal_status}")
            if new_wal_status != "wal":
                print("Avertissement: √âchec de l'activation WAL")

        # Statut final
        with sqlite3.connect(merged_db_path) as test_conn:
            test_cursor = test_conn.cursor()
            test_cursor.execute("SELECT 1 FROM sqlite_master LIMIT 1")
            db_status = "OK" if test_cursor.fetchone() else "ERREUR"
            print(f"\nStatut final DB: {db_status}")

        # R√©sum√©
        print("\nüéØ R√©sum√© final:")
        print(f"- Playlists max ID: {max_playlist_id}")
        print(f"- PlaylistItem total: {len(item_id_map)}")
        print(f"- M√©dias max ID: {max_media_id}")
        print(f"- Orphelins supprim√©s: {orphaned_deleted}")
        print(f"- R√©sultat int√©grit√©: {integrity_result}")
        print(">>> Fin de merge_playlists, on retourne les valeurs")
        print("‚úÖ Tous les calculs termin√©s, retour imminent")

        return max_playlist_id, len(item_id_map), max_media_id, orphaned_deleted, integrity_result, item_id_map

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"ERREUR CRITIQUE dans merge_playlists: {str(e)}")
        return None, 0, 0, 0, "error", {}

    finally:
        if conn:
            try:
                conn.close()
            except:
                pass


def create_note_mapping(merged_db_path, file1_db, file2_db):
    """Cr√©e un mapping (source_db_path, old_note_id) -> new_note_id en se basant sur les GUID."""
    mapping = {}
    try:
        with sqlite3.connect(merged_db_path, timeout=30) as merged_conn:
            merged_conn.execute("PRAGMA busy_timeout = 10000")
            merged_cursor = merged_conn.cursor()
            merged_cursor.execute("SELECT Guid, NoteId FROM Note")
            merged_guid_map = {guid: note_id for guid, note_id in merged_cursor.fetchall() if guid}

        for db_path in [file1_db, file2_db]:
            if not os.path.exists(db_path):
                print(f"[WARN] Fichier DB manquant : {db_path}")
                continue

            with sqlite3.connect(db_path) as src_conn:
                src_cursor = src_conn.cursor()
                src_cursor.execute("SELECT NoteId, Guid FROM Note")
                for old_note_id, guid in src_cursor.fetchall():
                    if guid and guid in merged_guid_map:
                        mapping[(db_path, old_note_id)] = merged_guid_map[guid]

    except Exception as e:
        print(f"[ERREUR] create_note_mapping: {str(e)}")

    return mapping or {}


@app.route('/merge', methods=['POST'])
def merge_data():
    # ‚îÄ‚îÄ‚îÄ 0. Initialisation des variables utilis√©es plus bas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    merged_jwlibrary = None
    max_playlist_id = 0
    max_media_id = 0
    orphaned_deleted = 0
    integrity_result = "ok"
    item_id_map = {}
    marker_id_map = {}
    playlist_id_map = {}

    conn = None  # pour le finally

    try:
        global note_mapping  # Si vous souhaitez utiliser le scope global (optionnel)
        payload = request.get_json()
        conflict_choices_notes = payload.get("conflicts_notes", {})
        conflict_choices_highlights = payload.get("conflicts_highlights", {})
        local_datetime = payload.get("local_datetime")
        print(f"local_datetime re√ßu du client : {local_datetime}")
        if local_datetime:
            merge_date = local_datetime if len(local_datetime) > 16 else local_datetime + ":00"
        else:
            merge_date = get_current_local_iso8601()

        file1_db = os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db")
        file2_db = os.path.join(EXTRACT_FOLDER, "file2_extracted", "userData.db")

        # Validation fichiers sources
        if not all(os.path.exists(db) for db in [file1_db, file2_db]):
            return jsonify({"error": "Fichiers source manquants"}), 400

        data1 = read_notes_and_highlights(file1_db)
        data2 = read_notes_and_highlights(file2_db)

        # Fusion simple des Notes et Highlights (vous pouvez conserver votre logique ici)
        notes_db1 = data1["notes"]
        notes_db2 = data2["notes"]
        merged_notes_list = []

        def format_note(db_path, note_row):
            # Cette fonction garantit que chaque note ait 10 champs
            (
                note_id,
                guid,
                title,
                content,
                old_loc_id,
                usermark_guid,
                last_modified,
                created,
                block_type,
                block_identifier
            ) = note_row
            return (
                db_path, guid, title, content,
                old_loc_id, usermark_guid,
                last_modified, created,
                block_type, block_identifier
            )

        # Ajout des notes du fichier 1
        for note in notes_db1:
            merged_notes_list.append(format_note(file1_db, note))

        # Ajout des notes du fichier 2 sans doublons
        for note in notes_db2:
            _, _, title2, content2, *_ = note
            existe = any(n[2] == title2 and n[3] == content2 for n in merged_notes_list)
            if not existe:
                merged_notes_list.append(format_note(file2_db, note))

        highlights_db1 = data1["highlights"]
        highlights_db2 = data2["highlights"]
        merged_highlights_dict = {}
        for h in highlights_db1:
            _, color, loc, style, guid, version = h
            merged_highlights_dict[guid] = (color, loc, style, version)
        for h in highlights_db2:
            _, color2, loc2, style2, guid2, version2 = h
            if guid2 not in merged_highlights_dict:
                merged_highlights_dict[guid2] = (color2, loc2, style2, version2)
            else:
                (color1, loc1, style1, version1) = merged_highlights_dict[guid2]
                if (color1 == color2 and loc1 == loc2 and style1 == style2 and version1 == version2):
                    continue
                else:
                    choice = conflict_choices_highlights.get(guid2, "file1")
                    if choice == "file2":
                        merged_highlights_dict[guid2] = (color2, loc2, style2, version2)

        # === Validation pr√©alable ===
        required_dbs = [
            os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db"),
            os.path.join(EXTRACT_FOLDER, "file2_extracted", "userData.db")
        ]
        if not all(os.path.exists(db) for db in required_dbs):
            return jsonify({"error": "Fichiers source manquants"}), 400

        # Cr√©ation de la DB fusionn√©e
        merged_db_path = os.path.join(UPLOAD_FOLDER, "merged_userData.db")
        if os.path.exists(merged_db_path):
            os.remove(merged_db_path)
        base_db_path = os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db")
        create_merged_schema(merged_db_path, base_db_path)

        # juste apr√®s create_merged_schema(merged_db_path, base_db_path)
        print("\n‚Üí Debug: listing des tables juste apr√®s create_merged_schema")
        with sqlite3.connect(merged_db_path) as dbg_conn:
            dbg_cur = dbg_conn.cursor()
            dbg_cur.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [t[0] for t in dbg_cur.fetchall()]
            print("Tables pr√©sentes dans merged_userData.db :", tables)

        # ... Apr√®s la cr√©ation de merged_db_path et avant la fusion des autres mappings
        # Fusion de la table IndependentMedia et PlaylistItems, etc.
        location_id_map = merge_location_from_sources(merged_db_path, *required_dbs)
        print("Location ID Map:", location_id_map)

        independent_media_map = merge_independent_media(merged_db_path, file1_db, file2_db)
        print("Mapping IndependentMedia:", independent_media_map)

        # ‚ùå NE PAS appeler merge_playlist_items ici
        # item_id_map = merge_playlist_items(...)

        usermark_guid_map = merge_usermark_from_sources(merged_db_path, file1_db, file2_db, location_id_map)

        # === INS√âRER LES USERMARKS AVANT DE FUSIONNER LES BLOCKRANGE ===
        conn = sqlite3.connect(merged_db_path)
        cursor = conn.cursor()

        for guid, (color, loc, style, version) in merged_highlights_dict.items():
            try:
                cursor.execute("""
                    INSERT OR IGNORE INTO UserMark (ColorIndex, LocationId, StyleIndex, UserMarkGuid, Version)
                    VALUES (?, ?, ?, ?, ?)
                """, (color, loc, style, guid, version))
            except Exception as e:
                print(f"Erreur lors de l'insertion de UserMarkGuid={guid}: {e}")

        conn.commit()
        conn.close()

        # === INS√âRER LES NOTES et USERMARK DANS LA DB FUSIONN√âE AVANT de cr√©er note_mapping ===
        conn = sqlite3.connect(merged_db_path)
        cursor = conn.cursor()
        # --- Insertion des NOTES dans merge_data (dans la boucle sur merged_notes_list)
        for note_tuple in merged_notes_list:
            old_db_path, guid, title, content, old_loc_id, usermark_guid, last_modified, created, block_type, block_identifier = note_tuple

            new_guid = guid if guid else str(uuid.uuid4())

            # Appliquer le mapping de LocationId
            normalized_key = (os.path.normpath(old_db_path), old_loc_id)
            normalized_location_map = {(os.path.normpath(k[0]), k[1]): v for k, v in location_id_map.items()}
            new_location_id = normalized_location_map.get(normalized_key)

            # Appliquer le mapping de UserMarkId si possible
            new_usermark_id = None
            if usermark_guid:
                cursor.execute("SELECT UserMarkId FROM UserMark WHERE UserMarkGuid = ?", (usermark_guid,))
                result = cursor.fetchone()
                if result:
                    new_usermark_id = result[0]

            # On va maintenant v√©rifier si une note avec ce GUID existe d√©j√† dans la DB fusionn√©e
            cursor.execute("SELECT Title, Content FROM Note WHERE Guid = ?", (new_guid,))
            existing = cursor.fetchone()

            if existing:
                if existing[0] == title and existing[1] == content:
                    # La note existe d√©j√† et est identique, on n'ins√®re rien
                    print(f"Note avec GUID {new_guid} d√©j√† pr√©sente et identique, insertion ignor√©e.")
                else:
                    # Conflit : le GUID existe, mais le contenu est diff√©rent.
                    # On g√©n√®re un nouveau GUID pour pr√©server l'information
                    new_guid_conflict = str(uuid.uuid4())
                    print(
                        f"Conflit pour GUID {new_guid}: contenu diff√©rent. Insertion de la note avec nouveau GUID {new_guid_conflict}.")
                    new_guid = new_guid_conflict  # On met √† jour pour cette insertion
                    cursor.execute("""
                        INSERT INTO Note (Guid, Title, Content, LocationId, UserMarkId, LastModified, Created, BlockType, BlockIdentifier)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        new_guid,
                        title,
                        content,
                        new_location_id,
                        new_usermark_id,
                        last_modified,
                        created,
                        block_type,
                        block_identifier
                    ))
            else:
                # Aucune note existante, on ins√®re directement
                cursor.execute("""
                    INSERT INTO Note (Guid, Title, Content, LocationId, UserMarkId, LastModified, Created, BlockType, BlockIdentifier)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    new_guid,
                    title,
                    content,
                    new_location_id,
                    new_usermark_id,
                    last_modified,
                    created,
                    block_type,
                    block_identifier
                ))

        # Gestion sp√©cifique de LastModified
        cursor.execute("DELETE FROM LastModified")
        cursor.execute("INSERT INTO LastModified (LastModified) VALUES (?)", (merge_date,))
        conn.commit()
        conn.close()

        # Apr√®s create_note_mapping‚Ä¶
        note_mapping = create_note_mapping(merged_db_path, file1_db, file2_db)
        print("Note Mapping:", note_mapping)

        # (R√©)ouvrir la connexion pour PlaylistItem
        conn = sqlite3.connect(merged_db_path)
        cursor = conn.cursor()

        # ‚Ä¶ juste apr√®s avoir construit note_mapping ‚Ä¶

        print("üîπ Avant merge_playlist_items :",
              conn.execute("SELECT COUNT(*) FROM PlaylistItem").fetchone()[0])

        # ‚îÄ‚îÄ‚îÄ 3. Fusion de la table PlaylistItem ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        item_id_map = merge_playlist_items(
            merged_db_path,
            file1_db,
            file2_db
        )

        # Affichage du contenu de PlaylistItem avec la bonne colonne
        for row in conn.execute("SELECT PlaylistItemId, Label FROM PlaylistItem ORDER BY PlaylistItemId"):
            print(row)

        print("üîπ Apr√®s merge_playlist_items :",
              conn.execute("SELECT COUNT(*) FROM PlaylistItem").fetchone()[0])

        print(f"--> PlaylistItem fusionn√©s : {len(item_id_map)} items")

        conn.close()

        print("\n=== USERMARK VERIFICATION ===")
        print(f"Total UserMarks mapp√©s (GUIDs) : {len(usermark_guid_map)}")
        with sqlite3.connect(merged_db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM UserMark")
            total = cursor.fetchone()[0]
            print(f"UserMarks dans la DB: {total}")
            cursor.execute("""
                SELECT ColorIndex, StyleIndex, COUNT(*) 
                FROM UserMark 
                GROUP BY ColorIndex, StyleIndex
            """)
            print("R√©partition par couleur/style:")
            for color, style, count in cursor.fetchall():
                print(f"- Couleur {color}, Style {style}: {count} marques")

        print(f"Location IDs mapp√©s: {location_id_map}")
        print(f"UserMark GUIDs mapp√©s: {usermark_guid_map}")

        # ===== V√©rification pr√©-fusion compl√®te =====
        print("\n=== VERIFICATION PRE-FUSION ===")
        print("\n[V√âRIFICATION FICHIERS SOURCES]")
        source_files = [
            os.path.join(EXTRACT_FOLDER, "file1_extracted", "userData.db"),
            os.path.join(EXTRACT_FOLDER, "file2_extracted", "userData.db")
        ]
        for file in source_files:
            print(f"V√©rification {file}... ", end="")
            if not os.path.exists(file):
                print("ERREUR: Fichier manquant")
                return jsonify({"error": f"Fichier source manquant: {file}"}), 400
            else:
                print(f"OK ({os.path.getsize(file) / 1024:.1f} KB)")

        print("\n[V√âRIFICATION SCH√âMA]")

        def verify_schema(db_path):
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [t[0] for t in cursor.fetchall()]
                print(f"Tables dans {os.path.basename(db_path)}: {len(tables)}")
                required_tables = {'Bookmark', 'Location', 'UserMark', 'Note'}
                missing = required_tables - set(tables)
                if missing:
                    print(f"  TABLES MANQUANTES: {missing}")
                conn.close()
                return not bool(missing)
            except Exception as e:
                print(f"  ERREUR: {str(e)}")
                return False
        if not all(verify_schema(db) for db in source_files):
            return jsonify({"error": "Sch√©ma de base de donn√©es incompatible"}), 400

        print("\n[V√âRIFICATION BASE DE DESTINATION]")
        print(f"V√©rification {merged_db_path}... ", end="")
        try:
            conn = sqlite3.connect(merged_db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [t[0] for t in cursor.fetchall()]
            print(f"OK ({len(tables)} tables)")
            conn.close()
        except Exception as e:
            print(f"ERREUR: {str(e)}")
            return jsonify({"error": "Base de destination corrompue"}), 500

        print("\n[V√âRIFICATION SYST√àME]")
        try:
            import psutil
            mem = psutil.virtual_memory()
            print(f"M√©moire disponible: {mem.available / 1024 / 1024:.1f} MB")
            if mem.available < 500 * 1024 * 1024:
                print("ATTENTION: M√©moire insuffisante")
        except ImportError:
            print("psutil non install√© - v√©rification m√©moire ignor√©e")

        print("\n=== PR√äT POUR FUSION ===\n")

        # --- FUSION BOOKMARKS ---
        merge_bookmarks(merged_db_path, file1_db, file2_db, location_id_map)

        # --- FUSION BLOCKRANGE ---
        print("\n=== DEBUT FUSION BLOCKRANGE ===")
        if not merge_blockrange_from_two_sources(merged_db_path, file1_db, file2_db):
            print("√âCHEC Fusion BlockRange")
            return jsonify({"error": "BlockRange merge failed"}), 500

        # Mapping inverse UserMarkId original ‚Üí nouveau
        usermark_guid_map = {}
        conn = sqlite3.connect(merged_db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT UserMarkId, UserMarkGuid FROM UserMark")
        for new_id, guid in cursor.fetchall():
            usermark_guid_map[guid] = new_id
        conn.close()

        # --- FUSION NOTES ---
        merge_notes(merged_db_path, file1_db, file2_db, location_id_map, usermark_guid_map)

        # --- √âtape 1 : fusion des Tags et TagMap (utilise location_id_map) ---
        try:
            tag_id_map, tagmap_id_map = merge_tags_and_tagmap(
                merged_db_path,
                file1_db,
                file2_db,
                note_mapping,
                location_id_map,
                item_id_map
            )
        except Exception as e:
            print(f"√âchec de merge_tags_and_tagmap: {str(e)}")
            return jsonify({"error": "√âchec de la fusion des tags"}), 500

        print(f"Tag ID Map: {tag_id_map}")
        print(f"TagMap ID Map: {tagmap_id_map}")

        # --- V√©rification Tag ---
        print("\n=== TAGS VERIFICATION ===")
        try:
            with sqlite3.connect(merged_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM Tag")
                tags_count = cursor.fetchone()[0]
                cursor.execute("SELECT COUNT(*) FROM TagMap")
                tagmaps_count = cursor.fetchone()[0]
                print(f"Tags: {tags_count}")
                print(f"TagMaps: {tagmaps_count}")
                cursor.execute("""
                    SELECT COUNT(*) 
                    FROM TagMap 
                    WHERE NoteId NOT IN (SELECT NoteId FROM Note)
                """)
                orphaned = cursor.fetchone()[0]
                print(f"TagMaps orphelins: {orphaned}")
        except Exception as e:
            print(f"‚ùå ERREUR dans la v√©rification des tags : {e}")
            import traceback
            traceback.print_exc()
            return jsonify({"error": "Erreur lors de la v√©rification des tags"}), 500

        print("\n‚ñ∂Ô∏è D√©but de la fusion des √©l√©ments li√©s aux playlists...")

        # Fusion de PlaylistItemAccuracy
        max_acc_id = merge_playlist_item_accuracy(merged_db_path, file1_db, file2_db)
        print(f"--> PlaylistItemAccuracy fusionn√©e, max ID final: {max_acc_id}")

        # Fusion de PlaylistItemLocationMap
        merge_playlist_item_location_map(merged_db_path, file1_db, file2_db, item_id_map, location_id_map)
        print("--> PlaylistItemLocationMap fusionn√©e.")

        # Fusion de PlaylistItemMediaMap
        merge_playlist_item_media_map(merged_db_path, file1_db, file2_db, item_id_map, independent_media_map)
        print("--> PlaylistItemMediaMap fusionn√©e.")

        # Fusion de PlaylistItemMarker et r√©cup√©ration du mapping des markers
        marker_id_map = merge_playlist_item_marker(merged_db_path, file1_db, file2_db, item_id_map)
        print(f"--> PlaylistItemMarker fusionn√©e, markers mapp√©s: {len(marker_id_map)}")

        # Fusion des MarkerMaps (BibleVerse, Paragraph, etc.)
        merge_marker_maps(merged_db_path, file1_db, file2_db, marker_id_map)
        print("--> MarkerMaps fusionn√©es.")

        # Fusion finale de la table Playlist
        playlist_id_map = merge_playlist_final(merged_db_path, file1_db, file2_db)
        print(f"--> Table Playlist fusionn√©e, playlists mapp√©es: {len(playlist_id_map)}")

        print("\n‚ñ∂Ô∏è Fusion des √©l√©ments li√©s aux playlists termin√©e.")

        # ‚îÄ‚îÄ‚îÄ Avant merge_other_tables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        tables_to_check = [
            'PlaylistItem',
            'IndependentMedia',
            'PlaylistItemLocationMap',
            'PlaylistItemIndependentMediaMap'
        ]
        print("\n--- COMPTES AVANT merge_other_tables ---")
        with sqlite3.connect(merged_db_path) as dbg_conn:
            dbg_cur = dbg_conn.cursor()
            for tbl in tables_to_check:
                # compte dans la base fusionn√©e
                dbg_cur.execute(f"SELECT COUNT(*) FROM {tbl}")
                cnt_merged = dbg_cur.fetchone()[0]
                # compte dans file1
                dbg_cur.execute(f"ATTACH DATABASE ? AS src1", (file1_db,))
                dbg_cur.execute(f"SELECT COUNT(*) FROM src1.{tbl}")
                cnt1 = dbg_cur.fetchone()[0]
                dbg_cur.execute("DETACH DATABASE src1")
                # compte dans file2
                dbg_cur.execute(f"ATTACH DATABASE ? AS src2", (file2_db,))
                dbg_cur.execute(f"SELECT COUNT(*) FROM src2.{tbl}")
                cnt2 = dbg_cur.fetchone()[0]
                dbg_cur.execute("DETACH DATABASE src2")
                print(f"[AVANT ] {tbl}: merged={cnt_merged}, file1={cnt1}, file2={cnt2}")

        # ‚îÄ‚îÄ‚îÄ Appel original ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        merge_other_tables(
            merged_db_path,
            file1_db,
            file2_db,
            exclude_tables=[
                'Note', 'UserMark', 'Location', 'BlockRange',
                'LastModified', 'Tag', 'TagMap', 'PlaylistItem',
                'InputField', 'Bookmark'
            ]
        )

        # ‚îÄ‚îÄ‚îÄ Apr√®s merge_other_tables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        print("\n--- COMPTES APR√àS merge_other_tables ---")
        with sqlite3.connect(merged_db_path) as dbg_conn:
            dbg_cur = dbg_conn.cursor()
            for tbl in tables_to_check:
                dbg_cur.execute(f"SELECT COUNT(*) FROM {tbl}")
                cnt_merged = dbg_cur.fetchone()[0]
                dbg_cur.execute(f"ATTACH DATABASE ? AS src1", (file1_db,))
                dbg_cur.execute(f"SELECT COUNT(*) FROM src1.{tbl}")
                cnt1 = dbg_cur.fetchone()[0]
                dbg_cur.execute("DETACH DATABASE src1")
                dbg_cur.execute(f"ATTACH DATABASE ? AS src2", (file2_db,))
                dbg_cur.execute(f"SELECT COUNT(*) FROM src2.{tbl}")
                cnt2 = dbg_cur.fetchone()[0]
                dbg_cur.execute("DETACH DATABASE src2")
                print(f"[APR√àS] {tbl}: merged={cnt_merged}, file1={cnt1}, file2={cnt2}")

        # 8. V√©rification finale des thumbnails
        print("\n[V√âRIFICATION THUMBNAILS ORPHELINS]")
        cursor.execute("""
                    SELECT p.PlaylistItemId, p.ThumbnailFilePath
                    FROM PlaylistItem p
                    WHERE p.ThumbnailFilePath IS NOT NULL
                      AND NOT EXISTS (
                          SELECT 1 FROM IndependentMedia m 
                          WHERE m.FilePath = p.ThumbnailFilePath
                      )
                """)
        orphaned_thumbnails = cursor.fetchall()
        if orphaned_thumbnails:
            print(f"Avertissement : {len(orphaned_thumbnails)} thumbnails sans m√©dia associ√©")

            # ‚úÖ Ajoute ceci ici (pas en dehors)
            conn.commit()

        # 9. Finalisation playlists
        print("\n=== FUSION PLAYLISTS TERMIN√âE ===")
        playlist_results = {
            'item_id_map': item_id_map,
            'marker_id_map': marker_id_map,
            'media_status': {
                'total_media': max_media_id,
                'orphaned_thumbnails': len(orphaned_thumbnails) if 'orphaned_thumbnails' in locals() else 0
            }
        }
        print(f"R√©sum√© interm√©diaire: {playlist_results}")

        # 10. (Optionnel) Fusion de la table Playlist si elle existe
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='Playlist'")
        has_playlist_table = cursor.fetchone() is not None

        if not has_playlist_table:
            print("üö´ Table 'Playlist' absente ‚Äî √©tape ignor√©e.")
        else:
            print("\n=== D√âBUT FUSION PLAYLIST ===")
            cursor.execute("SELECT MAX(PlaylistId) FROM Playlist")
            max_playlist_id = cursor.fetchone()[0] or 0
            print(f"ID max initial Playlist: {max_playlist_id}")
            playlist_id_map = {}

            for db_path in [file1_db, file2_db]:
                with sqlite3.connect(db_path) as source_conn:
                    source_cursor = source_conn.cursor()
                    source_cursor.execute("""
                                SELECT PlaylistId, Name, Description, IconId, OrderIndex, LastModified
                                FROM Playlist
                            """)
                    playlists = source_cursor.fetchall()
                    print(f"{len(playlists)} playlists trouv√©es dans {os.path.basename(db_path)}")

                    for pl_id, name, desc, icon, order_idx, modified in playlists:
                        original_name = name
                        suffix = 1
                        while True:
                            cursor.execute("SELECT 1 FROM Playlist WHERE Name = ?", (name,))
                            if not cursor.fetchone():
                                break
                            name = f"{original_name} ({suffix})"
                            suffix += 1

                        max_playlist_id += 1
                        try:
                            cursor.execute("""
                                        INSERT INTO Playlist
                                        (PlaylistId, Name, Description, IconId, OrderIndex, LastModified)
                                        VALUES (?, ?, ?, ?, ?, ?)
                                    """, (max_playlist_id, name, desc, icon, order_idx, modified))
                            playlist_id_map[(db_path, pl_id)] = max_playlist_id
                        except sqlite3.IntegrityError as e:
                            print(f"ERREUR Playlist {pl_id}: {str(e)}")

            print(f"Playlist fusionn√©e - ID max final: {max_playlist_id}")
            print(f"Total playlists fusionn√©es: {len(playlist_id_map)}")

        # 11. V√©rification de coh√©rence
        print("\n=== VERIFICATION COHERENCE ===")
        cursor.execute("""
            SELECT COUNT(*) 
              FROM PlaylistItem pi
             WHERE pi.PlaylistItemId NOT IN (
                    SELECT PlaylistItemId FROM PlaylistItemLocationMap
                    UNION
                    SELECT PlaylistItemId FROM PlaylistItemIndependentMediaMap
                )
        """)
        orphaned_items = cursor.fetchone()[0]
        status_color = "\033[91m" if orphaned_items > 0 else "\033[92m"
        print(f"{status_color}√âl√©ments sans parent d√©tect√©s (non supprim√©s) : {orphaned_items}\033[0m")

        # 12. Suppression des PlaylistItem orphelins
        with sqlite3.connect(merged_db_path) as conn_del:
            cur = conn_del.cursor()
            cur.execute("""
                DELETE FROM PlaylistItem
                 WHERE PlaylistItemId NOT IN (
                    SELECT PlaylistItemId FROM PlaylistItemLocationMap
                    UNION
                    SELECT PlaylistItemId FROM PlaylistItemIndependentMediaMap
                 )
            """)
            conn_del.commit()
        print("‚Üí PlaylistItem orphelins supprim√©s")

        # 13. Optimisations finales
        print("\n=== DEBUT OPTIMISATIONS ===")

        # D√©finition de log_message **avant** son premier appel
        log_file = os.path.join(UPLOAD_FOLDER, "fusion.log")

        def log_message(message, log_type="INFO"):
            print(message)
            with open(log_file, "a") as f:
                f.write(f"[{log_type}] {datetime.now().strftime('%H:%M:%S')} - {message}\n")

        # 13.1 Reconstruction des index
        print("\nReconstruction des index...")
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
        indexes = [row[0] for row in cursor.fetchall() if not row[0].startswith('sqlite_autoindex_')]
        for index_name in indexes:
            try:
                cursor.execute(f"REINDEX {index_name}")
                log_message(f"Index reconstruit: {index_name}")
            except sqlite3.Error as e:
                log_message(f"ERREUR sur index {index_name}: {str(e)}", "ERROR")

        # 13.2 V√©rification int√©grit√©
        print("\nV√©rification int√©grit√© base de donn√©es...")
        cursor.execute("PRAGMA quick_check")
        integrity_result = cursor.fetchone()[0]
        if integrity_result == "ok":
            log_message("Int√©grit√© de la base: OK")
        else:
            log_message(f"ERREUR int√©grit√©: {integrity_result}", "ERROR")

        # 13.3 V√©rification cl√©s √©trang√®res
        cursor.execute("PRAGMA foreign_key_check")
        fk_issues = cursor.fetchall()
        if fk_issues:
            log_message(f"ATTENTION: {len(fk_issues)} probl√®mes de cl√©s √©trang√®res", "WARNING")
            for issue in fk_issues[:3]:
                log_message(f"- Probl√®me: {issue}", "WARNING")
        else:
            log_message("Aucun probl√®me de cl√© √©trang√®re d√©tect√©")

        # 13.4 Optimisation finale
        print("\nOptimisation finale...")
        conn.commit()  # S'assurer de cl√¥turer la transaction en cours
        start_time = time.perf_counter()
        cursor.execute("VACUUM")
        cursor.execute("PRAGMA optimize")
        optimization_time = time.perf_counter() - start_time
        log_message(f"Optimisation termin√©e en {optimization_time:.2f}s")

        # --- 14. Finalisation ---
        # commit final et fermeture propre de la transaction playlists
        conn.commit()

        # R√©capitulatif final
        print("\n=== R√âCAPITULATIF FINAL ===")
        print(f"{'Playlists:':<20} {max_playlist_id}")
        print(f"{'√âl√©ments:':<20} {len(item_id_map)}")
        print(f"{'M√©dias:':<20} {max_media_id}")
        print(f"{'Nettoy√©s:':<20} {orphaned_deleted}")
        print(f"{'Int√©grit√©:':<20} {integrity_result}")
        if fk_issues:
            print(f"{'Probl√®mes FK:':<20} \033[91m{len(fk_issues)}\033[0m")
        else:
            print(f"{'Probl√®mes FK:':<20} \033[92mAucun\033[0m")

        # 16. Activation du WAL
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("CREATE TABLE IF NOT EXISTS dummy_for_wal (id INTEGER PRIMARY KEY)")
        cursor.execute("INSERT INTO dummy_for_wal DEFAULT VALUES")
        conn.commit()
        cursor.execute("DELETE FROM dummy_for_wal")
        conn.commit()
        cursor.execute("DROP TABLE dummy_for_wal")
        conn.commit()
        conn.close()

        # V√©rification du mode WAL
        with sqlite3.connect(merged_db_path) as test_conn:
            new_wal_status = test_conn.execute("PRAGMA journal_mode").fetchone()[0]
            print(f"Statut WAL apr√®s activation: {new_wal_status}")
            if new_wal_status != "wal":
                print("Avertissement: √âchec de l'activation WAL")

        print("üìç Avant le r√©sum√© final")

        print("‚ñ∂Ô∏è Appel de merge_playlists...")
        print("üõë merge_playlists appel√©e")

        try:
            (
                max_playlist_id,
                playlist_item_total,
                max_media_id,
                orphaned_deleted,
                integrity_result,
                item_id_map
            ) = merge_playlists(
                merged_db_path,
                file1_db,
                file2_db,
                location_id_map,
                independent_media_map,
                item_id_map  # ‚úÖ ajout√© ici
            )

            # üß™ R√©sum√© post merge_playlists
            print("\nüéØ R√©sum√© final apr√®s merge_playlists:")
            print(f"- Fichier fusionn√©: {merged_jwlibrary}")
            print(f"- Playlists max ID: {max_playlist_id}")
            print(f"- PlaylistItem total: {playlist_item_total}")
            print(f"- M√©dias max ID: {max_media_id}")
            print(f"- Orphelins supprim√©s: {orphaned_deleted}")
            print(f"- R√©sultat int√©grit√©: {integrity_result}")
            print("‚úÖ Tous les calculs termin√©s, nettoyage‚Ä¶")

            # 1Ô∏è‚É£ Mise √† jour des LocationId r√©siduels
            print("\n=== MISE √Ä JOUR DES LocationId R√âSIDUELS ===")
            merge_inputfields(merged_db_path, file1_db, file2_db, location_id_map)
            print("‚úî Fusion InputFields termin√©e")
            location_replacements_flat = {
                old_id: new_id
                for (_, old_id), new_id in sorted(location_id_map.items())
            }

            print("‚è≥ Appel de update_location_references...")
            try:
                update_location_references(merged_db_path, location_replacements_flat)
                print("‚úî Mise √† jour des r√©f√©rences LocationId termin√©e")
            except Exception as e:
                print(f"‚ùå ERREUR dans update_location_references : {e}")

            print("üü° Apr√®s update_location_references")
            sys.stdout.flush()
            time.sleep(0.5)
            print("üü¢ Avant suppression des tables MergeMapping_*")

            # 2Ô∏è‚É£ Suppression des tables MergeMapping_*
            print("\n=== SUPPRESSION DES TABLES MergeMapping_* ===")
            with sqlite3.connect(merged_db_path) as cleanup_conn:
                print("üîµ Connexion cleanup_conn ouverte")
                cur = cleanup_conn.cursor()
                cur.execute("""
                    SELECT name
                    FROM sqlite_master
                    WHERE type='table'
                      AND LOWER(name) LIKE 'mergemapping_%'
                """)
                rows = cur.fetchall()
                tables_to_drop = [row[0] for row in rows]
                print(f"üß™ R√©sultat brut de la requ√™te sqlite_master : {rows}")
                print(f"üßπ Tables MergeMapping_ d√©tect√©es : {tables_to_drop}")
                for tbl in tables_to_drop:
                    cur.execute(f"DROP TABLE IF EXISTS {tbl}")
                    print(f"‚úî Table supprim√©e : {tbl}")
                cleanup_conn.commit()

            # üîç V√©rification juste avant la copie
            print("üìÑ V√©rification taille et date de merged_userData.db juste avant la copie")
            print("üìç Fichier:", merged_db_path)
            print("üïí Modifi√© le:", os.path.getmtime(merged_db_path))
            print("üì¶ Taille:", os.path.getsize(merged_db_path), "octets")
            with sqlite3.connect(merged_db_path) as check_conn:
                cur = check_conn.cursor()
                cur.execute("SELECT name FROM sqlite_master WHERE name LIKE 'MergeMapping_%'")
                leftover = [row[0] for row in cur.fetchall()]
                print(f"üß™ Tables restantes juste avant la copie (v√©rification finale): {leftover}")

            print("üßπ Synchronisation finale de la base avant copie...")
            with sqlite3.connect(merged_db_path) as flush_conn:
                flush_conn.execute("VACUUM")  # force l‚Äô√©criture et nettoyage
                flush_conn.commit()
            print("üì¶ VACUUM termin√©, tous les changements doivent √™tre persist√©s.")

            # 3Ô∏è‚É£ Copier la DB propre dans UPLOAD_FOLDER
            final_db_dest = os.path.join(UPLOAD_FOLDER, "userData.db")
            shutil.copy(merged_db_path, final_db_dest)
            print(f"‚úÖ Copie vers UPLOAD_FOLDER r√©ussie : {final_db_dest}")

            # 4Ô∏è‚É£ V√©rification finale
            with sqlite3.connect(final_db_dest) as final_check:
                cur = final_check.cursor()
                cur.execute("SELECT name FROM sqlite_master WHERE name LIKE 'MergeMapping_%'")
                print("üìã Tables MergeMapping_ dans userData.db copi√© :", [row[0] for row in cur.fetchall()])

            # 5Ô∏è‚É£ Retour JSON final
            final_result = {
                "merged_file": "userData.db",
                "playlists": max_playlist_id,
                "playlist_items": playlist_item_total,
                "media_files": max_media_id,
                "cleaned_items": orphaned_deleted,
                "integrity_check": integrity_result
            }
            print("üéØ R√©sum√© final pr√™t √† √™tre envoy√© au frontend.")
            print("üß™ Test acc√®s √† final_result:", final_result)
            sys.stdout.flush()

            return jsonify(final_result), 200

        except Exception as e:
            import traceback
            print("‚ùå Exception lev√©e pendant merge_data !")
            traceback.print_exc()
            return jsonify({"error": f"Erreur dans merge_data: {str(e)}"}), 500

    finally:
        if conn:
            try:
                conn.close()
            except:
                pass


@app.route('/download', methods=['GET'])
def download_file():
    merged_db_path = os.path.join(UPLOAD_FOLDER, "merged_userData.db")
    if not os.path.exists(merged_db_path):
        return jsonify({"error": "Fichier fusionn√© non trouv√©."}), 404
    print("üì• Fichier envoy√© depuis :", merged_db_path)
    response = send_file(merged_db_path, as_attachment=True)
    response.headers.add("Access-Control-Allow-Origin", "*")
    return response


@app.errorhandler(Exception)
def handle_exception(e):
    response = jsonify({"error": str(e)})
    response.headers.add("Access-Control-Allow-Origin", "*")
    return response, 500


@app.route('/')
def home():
    return jsonify({"message": "Le serveur Flask fonctionne üéâ"})


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0')

